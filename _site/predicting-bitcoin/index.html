<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Predicting Bitcoin - Time Series Forecast - Sami’s Projects &amp; Notes</title>
<meta name="description" content="A compilation of my projects &amp; notes.">


  <meta name="author" content="Sami Kamal">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Sami's Projects & Notes">
<meta property="og:title" content="Predicting Bitcoin - Time Series Forecast">
<meta property="og:url" content="http://localhost:4000/predicting-bitcoin/">


  <meta property="og:description" content="A compilation of my projects &amp; notes.">



  <meta property="og:image" content="http://localhost:4000/images/bitcoin-images/bitcoin-banner.png">









  

  


<link rel="canonical" href="http://localhost:4000/predicting-bitcoin/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Sami Kamal",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Sami's Projects & Notes Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Sami's Projects & Notes
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/">Home</a>
            </li><li class="masthead__menu-item">
              <a href="/projects">Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/coursework">Coursework</a>
            </li><li class="masthead__menu-item">
              <a href="/Resume.pdf">Résumé</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: url('/images/bitcoin-images/bitcoin-banner.png');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Predicting Bitcoin - Time Series Forecast

        
      </h1>
      
      


      
      
    </div>
  
  
</div>







<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/images/smaglantis-images/PlayerHead.gif" alt="Sami Kamal" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Sami Kamal</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>My notes on math, computer science, and cognitive science.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://github.com/samikamal21" itemprop="sameAs" rel="nofollow noopener noreferrer me">
            <i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Predicting Bitcoin - Time Series Forecast">
    
    
    

    <div class="page__inner-wrap">
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Overview</h4></header>
              <ul class="toc__menu"><li><a href="#predicting-bitcoin">Predicting Bitcoin</a><ul><li><a href="#get-data">Get Data</a></li><li><a href="#importing-time-series-with-pandas">Importing time series with pandas</a></li><li><a href="#importing-time-series-data-with-pythons-csv-module">Importing time series data with Python’s CSV module</a></li><li><a href="#format-data-part-1-create-train-and-test-sets">Format Data Part 1: Create train and test sets</a></li><li><a href="#create-a-plotting-function">Create a plotting function</a></li><li><a href="#modelling-experiments">Modelling Experiments</a></li><li><a href="#model-0-naive-forecast-baseline">Model 0: Naive forecast (baseline)</a></li><li><a href="#evaluating-a-time-series-model">Evaluating a time series model</a></li><li><a href="#format-data-part-2-windowing-our-dataset">Format Data Part 2: Windowing our dataset</a></li><li><a href="#turning-windows-into-training-and-test-sets">Turning windows into training and test sets</a></li><li><a href="#make-a-modelling-checkpoint-callback">Make a modelling checkpoint callback</a></li><li><a href="#model-1-dense-model-window--7-horizon--1">Model 1: Dense model (window = 7, horizon = 1)</a></li><li><a href="#making-forecasts-with-a-model-on-the-test-dataset">Making forecasts with a model (on the test dataset)</a></li><li><a href="#model-2-dense-window--30-horizon--1">Model 2: Dense (window = 30, horizon = 1)</a></li><li><a href="#model-3-dense-window--30-horizon--7">Model 3: Dense (window = 30, horizon = 7)</a></li><li><a href="#make-our-evaluation-function-work-for-larger-horizons">Make our evaluation function work for larger horizons.</a></li><li><a href="#which-of-the-following-of-our-models-is-performing-the-best-so-far">Which of the following of our models is performing the best so far?</a></li><li><a href="#model-4-conv1d">Model 4: Conv1D</a></li><li><a href="#model-5-rnn-lstm">Model 5: RNN (LSTM)</a></li><li><a href="#make-a-multivariate-time-series-dataset">Make a multivariate time series dataset</a></li><li><a href="#making-a-windowed-dataset-with-pandas">Making a windowed dataset with pandas</a></li><li><a href="#model-6-dense-multivariate-time-series">Model 6: Dense (multivariate time series)</a></li><li><a href="#model-7-n-beats-algorithm">Model 7: N-BEATS Algorithm</a><ul><li><a href="#building-and-testing-the-n-beats-block-layer">Building and testing the N-BEATS Block Layer</a></li><li><a href="#preparing-data-for-the-n-beats-algorithm-using-tfdata">Preparing data for the N-BEATS algorithm using tf.data</a></li><li><a href="#setting-up-hyperparameters-for-n-beats-algorithm">Setting up hyperparameters for N-BEATS Algorithm</a></li><li><a href="#getting-ready-for-the-residual-connections">Getting ready for the residual connections</a></li><li><a href="#building-compiling-and-fitting-the-n-beats-algorithm">Building, compiling, and fitting the N-BEATS algorithm</a></li><li><a href="#plotting-the-n-beats-arhitecture-weve-created">Plotting the N-Beats arhitecture we’ve created</a></li></ul></li><li><a href="#model-8-creating-an-ensemble-stacking-different-models-together">Model 8: Creating an ensemble (stacking different models together)</a><ul><li><a href="#constructing-and-fitting-an-ensemble-of-models-using-different-loss-functions">Constructing and fitting an ensemble of models (using different loss functions)</a></li><li><a href="#make-predictions-with-our-ensemble-model">Make predictions with our ensemble model</a></li><li><a href="#plotting-the-prediction-intervals-uncertainty-estimates-of-our-ensemble">Plotting the prediction intervals (uncertainty estimates) of our ensemble</a></li></ul></li><li><a href="#aside-two-types-of-uncertainty-coconut-and-subway">Aside: two types of uncertainty (coconut and subway)</a></li><li><a href="#model-9-train-a-model-on-the-full-historical-data-to-make-predictions-into-the-future">Model 9: Train a model on the full historical data to make predictions into the future</a><ul><li><a href="#make-predictions-for-the-future">Make predictions for the future</a></li><li><a href="#plot-future-forecasts">Plot future forecasts</a></li></ul></li><li><a href="#model-10-why-forecasting-is-bs-the-turkey-problem">Model 10: Why forecasting is BS (The Turkey Problem)</a></li><li><a href="#build-a-turkey-model-model-to-predict-on-turkey">Build a turkey model (model to predict on turkey)</a><ul><li><a href="#compare-models">Compare models</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#the-full-code">The Full Code</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <style type="text/css">
body {
  font-size: 13pt;
}
</style>

<h1 id="predicting-bitcoin">Predicting Bitcoin</h1>

<p>For this project, we will be experimenting with many neural networks in order to predict the price of Bitcoin using TensorFlow.</p>

<p><strong>DISCLAIMER:</strong> THIS IS NOT FINANCIAL ADVICE, PLEASE INVEST AT YOUR OWN RISK.</p>

<h2 id="get-data">Get Data</h2>

<p>We’re going to be using the historical price data of Bitcoin to try and predict the future of Bitcoin. The data used in this project can be found <a href="https://www.coindesk.com/price/bitcoin/">here</a>.</p>

<h2 id="importing-time-series-with-pandas">Importing time series with pandas</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import with pandas
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Let's read in our Bitcoin data and parse the dates
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv</span><span class="sh">"</span><span class="p">,</span>
                   <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Date</span><span class="sh">"</span><span class="p">],</span>
                   <span class="n">index_col</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Date</span><span class="sh">"</span><span class="p">])</span> <span class="c1"># parse the data column and tell pandas column 1 is a datetime
</span><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<p><img src="/images/bitcoin-images/df.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output:</code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
DatetimeIndex: 2787 entries, 2013-10-01 to 2021-05-18
Data columns (total 5 columns):
 #   Column               Non-Null Count  Dtype  
---  ------               --------------  -----  
 0   Currency             2787 non-null   object 
 1   Closing Price (USD)  2787 non-null   float64
 2   24h Open (USD)       2787 non-null   float64
 3   24h High (USD)       2787 non-null   float64
 4   24h Low (USD)        2787 non-null   float64
dtypes: float64(4), object(1)
memory usage: 130.6+ KB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/df-tail.png" alt="" /></p>

<p>We’ve collected the historical price of Bitcoin for ~8 years but there are 2787 samples.</p>

<p>Typically, deep learning models usually like a lot of samples (tens of thousands to millions).</p>

<p>A smaller number of samples is a common problem in time series problems.</p>

<blockquote>
  <p><strong>Note:</strong> The <strong>seasonality</strong> of a time series dataset is referred as the number of samples per year. So for the Bitcoin data, it has a seasonality of daily or value of 365 since one sample is collected a day, which only means you’ll get 365 per year.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Only want closing price for each day
</span><span class="n">bitcoin_prices</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">Closing Price (USD)</span><span class="sh">"</span><span class="p">]).</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">Closing Price (USD)</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">})</span>
<span class="n">bitcoin_prices</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Date	       Price
2013-10-01	123.65499
2013-10-02	125.45500
2013-10-03	108.58483
2013-10-04	118.67466
2013-10-05	121.33866
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">bitcoin_prices</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">BTC Price</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Price of Bitcoin from 1 Oct 2013 to 18 May 2021</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span> 
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<p><img src="/images/bitcoin-images/graph1.png" alt="" /></p>

<h2 id="importing-time-series-data-with-pythons-csv-module">Importing time series data with Python’s CSV module</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Importing and formatting historical Bitcoin data with Python
</span><span class="kn">import</span> <span class="n">csv</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">timesteps</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">btc_price</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">csv_file</span><span class="p">:</span>
  <span class="n">csv_reader</span> <span class="o">=</span> <span class="n">csv</span><span class="p">.</span><span class="nf">reader</span><span class="p">(</span><span class="n">csv_file</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">)</span>
  <span class="nf">next</span><span class="p">(</span><span class="n">csv_reader</span><span class="p">)</span> <span class="c1"># skip first line (this gets rid of the column titles)
</span>
  <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">csv_reader</span><span class="p">:</span>
    <span class="n">timesteps</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">datetime</span><span class="p">.</span><span class="nf">strptime</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="sh">"</span><span class="s">%Y-%m-%d</span><span class="sh">"</span><span class="p">))</span> <span class="c1"># get the dates as dates (not strings)
</span>    <span class="n">btc_price</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span> <span class="c1"># get the closing price as a float
</span>
<span class="c1"># View first 10 of each
</span><span class="n">timesteps</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">btc_price</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>([datetime.datetime(2013, 10, 1, 0, 0),
  datetime.datetime(2013, 10, 2, 0, 0),
  datetime.datetime(2013, 10, 3, 0, 0),
  datetime.datetime(2013, 10, 4, 0, 0),
  datetime.datetime(2013, 10, 5, 0, 0),
  datetime.datetime(2013, 10, 6, 0, 0),
  datetime.datetime(2013, 10, 7, 0, 0),
  datetime.datetime(2013, 10, 8, 0, 0),
  datetime.datetime(2013, 10, 9, 0, 0),
  datetime.datetime(2013, 10, 10, 0, 0)],
 [123.65499,
  125.455,
  108.58483,
  118.67466,
  121.33866,
  120.65533,
  121.795,
  123.033,
  124.049,
  125.96116])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot from CSV
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">btc_price</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">BTC Price</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Price of Bitcoin from 1 Oct 2013 to 18 May 2021</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<p><img src="/images/bitcoin-images/graph2.png" alt="" /></p>

<h2 id="format-data-part-1-create-train-and-test-sets">Format Data Part 1: Create train and test sets</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create train and test splits
</span><span class="n">split_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">prices</span><span class="p">))</span> <span class="c1"># 80% train, 20% test
</span>
<span class="c1"># Create train data splits (everything before the split)
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">timesteps</span><span class="p">[:</span><span class="n">split_size</span><span class="p">],</span> <span class="n">prices</span><span class="p">[:</span><span class="n">split_size</span><span class="p">]</span>

<span class="c1"># Create test and data splits (everything beyond the split)
</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">timesteps</span><span class="p">[</span><span class="n">split_size</span><span class="p">:],</span> <span class="n">prices</span><span class="p">[</span><span class="n">split_size</span><span class="p">:]</span>

<span class="c1"># Plot splits
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Train data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Date</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">BTC Price</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<p><img src="/images/bitcoin-images/graph3.png" alt="" /></p>

<h2 id="create-a-plotting-function">Create a plotting function</h2>

<p>Typing plotting code is tedius, let’s functionize it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a function to plot time series data
</span><span class="k">def</span> <span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Plots a timesteps (a series of points in time) against values (a series of values across timesteps).

  Parameters
  ---------
  timesteps : array of timesteps
  values : array of values across time
  format : style of plot, default </span><span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="s">
  start : where to start the plot (setting a value will index from start of timesteps &amp; values)
  end : where to end the plot (setting a value will index from end of timesteps &amp; values)
  label : label to show on plot of values
  </span><span class="sh">"""</span>
  <span class="c1"># Plot the series
</span>  <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span> <span class="n">values</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span> <span class="nb">format</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Time</span><span class="sh">"</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">BTC Price</span><span class="sh">"</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">label</span><span class="p">:</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span> <span class="c1"># make label bigger
</span>  <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Test our plotting function
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Train data</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test data</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<p><img src="/images/bitcoin-images/graph4.png" alt="" /></p>

<h2 id="modelling-experiments">Modelling Experiments</h2>

<p>We’ve got some Bitcoin historical data, to model it, let’s run a series of modeling experiments and see which model performs best.</p>

<p>Terms to be familiar with:</p>
<ul>
  <li><strong>Horizon</strong> = number of timesteps into the future we’re going to predict</li>
  <li><strong>Window size</strong> = number of timesteps we’re going to use to predict horizon</li>
</ul>

<p>Modelling experiments we’re running:</p>
<ul>
  <li>0 Naïve model (baseline)</li>
  <li>1 Dense model, horizon = 1, window = 7</li>
  <li>2 Same as 1, horizon = 1, window = 30</li>
  <li>3 Same as 1, horizon = 7, window = 30</li>
  <li>4 Conv1D</li>
  <li>5 LSTM</li>
  <li>6 Same as 1 (but with multivariate data)</li>
  <li>7 N-BEATS Algorithm</li>
  <li>8 Ensemble (multiple models optimized on different loss functions)</li>
  <li>9 Future prediction model (model to predict future values)</li>
  <li>10 Same as 1 (but with turkey data introduced)</li>
</ul>

<h2 id="model-0-naive-forecast-baseline">Model 0: Naive forecast (baseline)</h2>

<p>Naive Bitcoin forecasting is a basic method that uses historical Bitcoin prices to make predictions. It operates on the assumption that the future price will be the same as the most recent price available in the data.</p>

<p>This approach is easy to apply and provides a quick initial estimate. However, it’s important to note that naive forecasting doesn’t account for complex factors like market trends, news events, or underlying patterns, which can lead to less accurate predictions when compared to more sophisticated forecasting methods.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a naive forecast
</span><span class="n">naive_forecast</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Plot naive forecast
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="c1"># plot_time_series(timesteps=X_train, values=y_train, label="Train data")
</span><span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test data</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">values</span><span class="o">=</span><span class="n">naive_forecast</span><span class="p">,</span><span class="n">start</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Naive Forecast</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/naive-forecast.png" alt="" /></p>

<h2 id="evaluating-a-time-series-model">Evaluating a time series model</h2>

<p>Let’s look into some evaluation metrics for time series forecasting.</p>

<p>We’re predicting a number, so that means we have a form of a regression problem.</p>

<p>Because we’re working on a regression problem, we’ll need some regression-like metrics.</p>

<p>A few common regression metrics (which can also be used for time series forecasting):</p>
<ul>
  <li>MAE - mean absolute error</li>
  <li>MSE - mean squared error</li>
  <li>RMSE - root mean square error</li>
  <li>MAPE/sMAPE - (symmetric) mean absolute percentage error</li>
  <li>MASE - mean absolute scaled error</li>
</ul>

<p>The lower the value is, the better.</p>

<p>The main thing we’re evaluating here is: <strong>How do our model’s forecasts (y_pred) compare against the actual values (y_true or ground truth values)?</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># MASE implementation
</span><span class="k">def</span> <span class="nf">mean_absolute_scaled_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="n">mae</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">y_true</span><span class="o">-</span><span class="n">y_pred</span><span class="p">))</span>

  <span class="c1"># Find MAE of naive forecast (no seasonality)
</span>  <span class="n">mae_naive_no_season</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="c1"># our seasonality is 1 day (hence the shift of 1)
</span>
  <span class="k">return</span> <span class="n">mae</span> <span class="o">/</span> <span class="n">mae_naive_no_season</span>

<span class="nf">mean_absolute_scaled_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">naive_forecast</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: 0.9995699939182624</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a function to take in model predictions and truth values and return evaluation metics
</span><span class="k">def</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Return a dictionary of evaluation metrics
  </span><span class="sh">"""</span>
  <span class="c1"># Make sure float32 dtype (for metric calculations)
</span>  <span class="n">y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

  <span class="c1"># Calculate metrics
</span>  <span class="n">mae</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
  <span class="n">mse</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
  <span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
  <span class="n">mape</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
  <span class="n">mase</span> <span class="o">=</span> <span class="nf">mean_absolute_scaled_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

  <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">:</span> <span class="n">mae</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="p">:</span> <span class="n">mse</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">rmse</span><span class="sh">"</span><span class="p">:</span> <span class="n">rmse</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">mape</span><span class="sh">"</span><span class="p">:</span> <span class="n">mape</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">mase</span><span class="sh">"</span><span class="p">:</span> <span class="n">mase</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()}</span>

  <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></div>

<p>Let’s now test and see if our method can evaluate our baseline.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">naive_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                               <span class="n">y_pred</span><span class="o">=</span><span class="n">naive_forecast</span><span class="p">)</span>
<span class="n">naive_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 567.9802,
 'mse': 1147547.0,
 'rmse': 1071.2362,
 'mape': 2.516525,
 'mase': 0.99957}
</code></pre></div></div>

<p>The mae here tells us that on average, our baseline is $567 off the actual value.</p>

<h2 id="format-data-part-2-windowing-our-dataset">Format Data Part 2: Windowing our dataset</h2>

<p>Why do we window?</p>

<p>We window our time series dataset to turn our data into a supervised learning problem.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Windowing for one week
[0, 1, 2, 3, 4, 5, 6] -&gt; [7]
[1, 2, 3, 4, 5, 6, 7] -&gt; [8]
[2, 3, 4, 5, 6, 7, 8] -&gt; [9]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># What we want to do with our Bitcoin data
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">We want to use: </span><span class="si">{</span><span class="n">btc_price</span><span class="p">[</span><span class="si">:</span><span class="mi">7</span><span class="p">]</span><span class="si">}</span><span class="s"> to predict this: </span><span class="si">{</span><span class="n">btc_price</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: We want to use: [123.65499, 125.455, 108.58483, 118.67466, 121.33866, 120.65533, 121.795] to predict this: 123.033</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Let's setup global variables for window and horizon size
</span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># predict next 1 day
</span><span class="n">WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">7</span> <span class="c1"># use the past week of Bitcoin data to make the prediction
</span>
<span class="c1"># Create function to label windowed data
</span><span class="k">def</span> <span class="nf">get_labelled_windows</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Creates labels for windowed dataset.

  E.g. if horizon=1
  Input: [0, 1, 2, 3, 4, 5, 6, 7] -&gt; Output: ([0, 1, 2, 3, 4, 5, 6], [7])
  </span><span class="sh">"""</span>

  <span class="k">return</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="n">horizon</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="n">horizon</span><span class="p">:]</span>

<span class="c1"># Test our the window labelling function
</span><span class="n">test_window</span><span class="p">,</span> <span class="n">test_label</span> <span class="o">=</span> <span class="nf">get_labelled_windows</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Window: </span><span class="si">{</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_window</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span><span class="si">}</span><span class="s"> -&gt; Label: </span><span class="si">{</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_label</span><span class="p">.</span><span class="nf">numpy</span><span class="p">())</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: Window: [0 1 2 3 4 5 6] -&gt; Label: 7</code></p>

<p>We’ve got a way to label our windowed data.</p>

<p>However, this only works on a small scale.</p>

<p>We need a way to do the above across our entire time series.</p>

<p>We could do this with Python for loops however, for a large time series dataset, the run time will be too slow.</p>

<p>To speed things up, we’ll leverage <a href="https://numpy.org/doc/stable/user/basics.indexing.html">NumPy’s array indexing</a>.</p>

<p>Our function will do the following steps:</p>
<ol>
  <li>
    <p>Create a window step of a specific window size (e.g. [0, 1, 2, 3, 4, 5, 6]).</p>
  </li>
  <li>
    <p>Use NumPy indexing to create a 2D array of multiple window steps, for example:</p>
  </li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[0, 1, 2, 3, 4, 5, 6],
[1, 2, 3, 4, 5, 6, 7],
[2, 3, 4, 5, 6, 7, 8]]
</code></pre></div></div>
<ol>
  <li>
    <p>Uses the 2D array of multiple window steps (from 2.) to index on a target series (e.g. the historical price of Bitcoin).</p>
  </li>
  <li>
    <p>Uses our <code class="language-plaintext highlighter-rouge">get_labelled_windows()</code> function we created above to turn the windows steps into windows with a specified horizon.</p>
  </li>
</ol>

<blockquote>
  <p>The function we’re about to create has been adapted from the following <a href="https://towardsdatascience.com/fast-and-robust-sliding-window-vectorization-with-numpy-3ad950ed62f5">article</a>.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create function to view NumPy arrays as windows
</span><span class="k">def</span> <span class="nf">make_windows</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Turns a 1D array into a 2D array of sequential labelled windows of window_size with horizon size labels.
  </span><span class="sh">"""</span>
  <span class="c1"># 1. Create a window of specific window_size (add the horizon on the end for labelling later)
</span>  <span class="n">window_step</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">window_size</span><span class="o">+</span><span class="n">horizon</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="c1"># 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)
</span>  <span class="n">window_indexs</span> <span class="o">=</span> <span class="n">window_step</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="n">window_size</span><span class="o">+</span><span class="n">horizon</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">T</span> <span class="c1"># create 2D array of windows of size window_size
</span>  <span class="c1"># print(f"Window indexes:\n {window_indexs, window_indexs.shape}")
</span>
  <span class="c1"># 3. Index on the target array (a time series) with 2D array of multiple window steps
</span>  <span class="n">windowed_array</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">window_indexs</span><span class="p">]</span>
  <span class="c1"># print(windowed_array)
</span>
  <span class="c1"># 4. Get the labelled windows
</span>  <span class="n">windows</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">get_labelled_windows</span><span class="p">(</span><span class="n">windowed_array</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="n">horizon</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">windows</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div></div>

<p>Essentially here is what is going on in this method:</p>

<p>Let’s say we have the following setup:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">x</code> is your data array, let’s assume it’s <code class="language-plaintext highlighter-rouge">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</code>.</li>
  <li>window_size is 3.</li>
  <li>horizon is 1.</li>
</ul>

<p>First, we create window_step:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">window_step = np.expand_dims(np.arange(window_size + horizon), axis=0)</code></li>
  <li>This results in <code class="language-plaintext highlighter-rouge">window_step = [[0, 1, 2, 3]]</code>. This is a template for a single window.</li>
</ul>

<p>Now, let’s look at the critical part: creating the <code class="language-plaintext highlighter-rouge">window_indexs</code> array.</p>

<ol>
  <li>Calculate Number of Windows:</li>
</ol>

<ul>
  <li><code class="language-plaintext highlighter-rouge">len(x) - (window_size + horizon - 1)</code> calculates how many windows we can create.</li>
  <li>For our <code class="language-plaintext highlighter-rouge">x</code>, this is 10 - (3 + 1 - 1) = 7. So, we can create 7 windows.</li>
</ul>

<ol>
  <li>Starting Indices for Each Window:</li>
</ol>

<ul>
  <li><code class="language-plaintext highlighter-rouge">np.arange(len(x)-(window_size+horizon-1))</code> creates an array of starting indices.</li>
  <li>In our case, this is <code class="language-plaintext highlighter-rouge">[0, 1, 2, 3, 4, 5, 6]</code>.</li>
</ul>

<ol>
  <li>Expanding and Transposing:</li>
</ol>

<p>We convert this to a 2D column vector: <code class="language-plaintext highlighter-rouge">[[0], [1], [2], [3], [4], [5], [6]]</code>.</p>

<ol>
  <li>Adding Window Indices:</li>
</ol>

<ul>
  <li>Now, for each start index, we add the <code class="language-plaintext highlighter-rouge">window_step</code>.</li>
  <li>When we add <code class="language-plaintext highlighter-rouge">[[0, 1, 2, 3]]</code> to <code class="language-plaintext highlighter-rouge">[[0], [1], [2], [3], [4], [5], [6]]</code>, it’s like adding 0 to the first row, 1 to the second row, and so on.</li>
</ul>

<p>This addition works due to broadcasting in NumPy. The <code class="language-plaintext highlighter-rouge">window_step</code> is added to each row of the start indices array. The result is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
 [0+0, 0+1, 0+2, 0+3],
 [1+0, 1+1, 1+2, 1+3],
 [2+0, 2+1, 2+2, 2+3],
 ...
 [6+0, 6+1, 6+2, 6+3]
]
</code></pre></div></div>

<p>Which can further be simplified to:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
 [0, 1, 2, 3],
 [1, 2, 3, 4],
 [2, 3, 4, 5],
 ...
 [6, 7, 8, 9]
]
</code></pre></div></div>

<p>Each row in this final array is a set of indices that corresponds to a window in your data x. For instance, the first row <code class="language-plaintext highlighter-rouge">[0, 1, 2, 3]</code> tells you that the first window should contain the elements <code class="language-plaintext highlighter-rouge">x[0], x[1], x[2], x[3]</code>, which are <code class="language-plaintext highlighter-rouge">[0, 1, 2, 3]</code>. Now, let’s create windows for our data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">full_windows</span><span class="p">,</span> <span class="n">full_labels</span> <span class="o">=</span> <span class="nf">make_windows</span><span class="p">(</span><span class="n">prices</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">)</span>

<span class="c1"># View the first 3 windows/labels
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
  <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Window: </span><span class="si">{</span><span class="n">full_windows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s"> -&gt; Label: </span><span class="si">{</span><span class="n">full_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Window: [123.65499 125.455   108.58483 118.67466 121.33866 120.65533 121.795  ] -&gt; Label: [123.033]
Window: [125.455   108.58483 118.67466 121.33866 120.65533 121.795   123.033  ] -&gt; Label: [124.049]
Window: [108.58483 118.67466 121.33866 120.65533 121.795   123.033   124.049  ] -&gt; Label: [125.96116]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># View the last 3 windows/labels
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
  <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Window: </span><span class="si">{</span><span class="n">full_windows</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s"> -&gt; Label: </span><span class="si">{</span><span class="n">full_labels</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Window: [58788.20967893 58102.19142623 55715.54665129 56573.5554719
 52147.82118698 49764.1320816  50032.69313676] -&gt; Label: [47885.62525472]
Window: [58102.19142623 55715.54665129 56573.5554719  52147.82118698
 49764.1320816  50032.69313676 47885.62525472] -&gt; Label: [45604.61575361]
Window: [55715.54665129 56573.5554719  52147.82118698 49764.1320816
 50032.69313676 47885.62525472 45604.61575361] -&gt; Label: [43144.47129086]
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> There’s a function that does something similar to the above in <code class="language-plaintext highlighter-rouge">tf.keras.preprocessing</code> which can be found <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array">here</a>.</p>
</blockquote>

<h2 id="turning-windows-into-training-and-test-sets">Turning windows into training and test sets</h2>

<p>Now, we need to split our data into training and testing data so we can create a pseudo future for our model to evaluate.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make the train/test splits
</span><span class="k">def</span> <span class="nf">make_train_test_splits</span><span class="p">(</span><span class="n">windows</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Splits matching pairs of windows and labels into train and test splits.
  </span><span class="sh">"""</span>
  <span class="n">split_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">windows</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">test_split</span><span class="p">))</span> <span class="c1"># this will default to 80% train and 20% test
</span>
  <span class="c1"># Create training set
</span>  <span class="n">train_windows</span> <span class="o">=</span> <span class="n">windows</span><span class="p">[:</span><span class="n">split_size</span><span class="p">]</span>
  <span class="n">train_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:</span><span class="n">split_size</span><span class="p">]</span>

  <span class="c1"># Create testing set
</span>  <span class="n">test_windows</span> <span class="o">=</span> <span class="n">windows</span><span class="p">[</span><span class="n">split_size</span><span class="p">:]</span>
  <span class="n">test_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">split_size</span><span class="p">:]</span>

  <span class="k">return</span> <span class="n">train_windows</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span>

<span class="c1"># Create train and test windows
</span><span class="n">train_windows</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="nf">make_train_test_splits</span><span class="p">(</span><span class="n">full_windows</span><span class="p">,</span> <span class="n">full_labels</span><span class="p">)</span>
<span class="n">train_windows</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">train_labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([[123.65499, 125.455  , 108.58483, 118.67466, 121.33866, 120.65533,
         121.795  ],
        [125.455  , 108.58483, 118.67466, 121.33866, 120.65533, 121.795  ,
         123.033  ],
        [108.58483, 118.67466, 121.33866, 120.65533, 121.795  , 123.033  ,
         124.049  ],
        [118.67466, 121.33866, 120.65533, 121.795  , 123.033  , 124.049  ,
         125.96116],
        [121.33866, 120.65533, 121.795  , 123.033  , 124.049  , 125.96116,
         125.27966]]),
 array([[123.033  ],
        [124.049  ],
        [125.96116],
        [125.27966],
        [125.9275 ]]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check out first 5 samples of testing data
</span><span class="n">test_windows</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">test_labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([[9290.89660239, 9202.41545055, 9369.62808116, 9326.59962378,
         9335.75240233, 9226.48582088, 8794.35864452],
        [9202.41545055, 9369.62808116, 9326.59962378, 9335.75240233,
         9226.48582088, 8794.35864452, 8798.04205463],
        [9369.62808116, 9326.59962378, 9335.75240233, 9226.48582088,
         8794.35864452, 8798.04205463, 9081.18687849],
        [9326.59962378, 9335.75240233, 9226.48582088, 8794.35864452,
         8798.04205463, 9081.18687849, 8711.53433917],
        [9335.75240233, 9226.48582088, 8794.35864452, 8798.04205463,
         9081.18687849, 8711.53433917, 8760.89271814]]),
 array([[8798.04205463],
        [9081.18687849],
        [8711.53433917],
        [8760.89271814],
        [8749.52059102]]))
</code></pre></div></div>

<h2 id="make-a-modelling-checkpoint-callback">Make a modelling checkpoint callback</h2>

<p>Because our model’s performance will fluctuate from experiment to experiment, we’re going to write a model checkpoint so we can compare apples to apples.</p>

<p>More specifically, we want to compare each of our model’s best performances against the other model’s best performances.</p>

<p>For example, if our model performs the best on epoch 55 (but we’re training for 100 epochs), we want to load and evaluate the model saved on epoch 55.</p>

<p>We can create a modelling checkpoint callback. For more details, click <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>

<span class="c1"># Create a function to implement a ModelCheckpoint callback with a specific filename
</span><span class="k">def</span> <span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="sh">"</span><span class="s">model_experiments</span><span class="sh">"</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">),</span>
                                            <span class="n">monitor</span><span class="o">=</span><span class="sh">"</span><span class="s">val_loss</span><span class="sh">"</span><span class="p">,</span>
                                            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                            <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="model-1-dense-model-window--7-horizon--1">Model 1: Dense model (window = 7, horizon = 1)</h2>

<p>Our first deep model is going to be a simple dense model:</p>
<ul>
  <li>A single dense layer with 128 hidden units and ReLU</li>
  <li>An output layer with linear activation (no activation)</li>
  <li>Adam optimization and MAE loss function</li>
  <li>Batch size of 128</li>
</ul>

<p>Why these values?</p>

<p>These values were picked from experimentation.</p>

<ul>
  <li><strong>Hyperparameters</strong> = values a machine learning practitioner can adjust themselves</li>
  <li><strong>Parameters</strong> = values a model learns on its own</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="c1"># Set random seed to reproduce results
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 1. Consturct the model
</span><span class="n">model_1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_1_dense</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Compile the model
</span><span class="n">model_1</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># 3. Fit the model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model_1</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_windows</span><span class="p">,</span>
                      <span class="n">y</span><span class="o">=</span><span class="n">train_labels</span><span class="p">,</span>
                      <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                      <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
                      <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_1</span><span class="p">.</span><span class="n">name</span><span class="p">)])</span>

<span class="c1"># Evaluate model on test data
</span><span class="n">model_1</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 5ms/step - loss: 623.0991 - mae: 623.0991 - mse: 1280242.3750
[623.09912109375, 623.09912109375, 1280242.375]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load in saved best performing model_1 and evaluate it on test data
</span><span class="n">model_1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/model_experiments/model_1_dense/</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model_1</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 3ms/step - loss: 573.9113 - mae: 573.9113 - mse: 1186394.6250
[573.9112548828125, 573.9112548828125, 1186394.625]
</code></pre></div></div>

<h2 id="making-forecasts-with-a-model-on-the-test-dataset">Making forecasts with a model (on the test dataset)</h2>

<p>To make “forecasts” on the test dataset (note: these won’t be actual forecasts, they’re only pseudo forecasts because actual forecasts are into the future.), let’s write a function to:</p>

<ol>
  <li>Take in a trained model</li>
  <li>Takes in some input data (the same kind of data the model was trained on)</li>
  <li>Passes the input data to the model’s <code class="language-plaintext highlighter-rouge">predict()</code> method</li>
  <li>Returns the predictions</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_data</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Uses model to make predictions on input_data.
  </span><span class="sh">"""</span>
  <span class="n">forecast</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">forecast</span><span class="p">)</span> <span class="c1"># return 1d array of predictions
</span>
<span class="c1"># Make predictions using model_1 on the test dataset and view results
</span><span class="n">model_1_preds</span> <span class="o">=</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">)</span>
<span class="n">model_1_preds</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="nf">len</span><span class="p">(</span><span class="n">model_1_preds</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(&lt;tf.Tensor: shape=(10,), dtype=float32, numpy=
 array([8878.352, 8766.737, 9047.672, 8795.976, 8706.521, 8783.352,
        8687.99 , 8510.261, 8478.368, 8532.557], dtype=float32)&gt;,
 556)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Evaluate preds
</span><span class="n">model_1_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_labels</span><span class="p">),</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_1_preds</span><span class="p">)</span>
<span class="n">model_1_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 573.91125,
 'mse': 1186394.6,
 'rmse': 1089.2174,
 'mape': 2.5553186,
 'mase': 1.0082031}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">naive_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 567.9802,
 'mse': 1147547.0,
 'rmse': 1071.2362,
 'mape': 2.516525,
 'mase': 0.99957}
</code></pre></div></div>

<p>The mae in <code class="language-plaintext highlighter-rouge">model_1</code> did not perform as well as the <code class="language-plaintext highlighter-rouge">naive_results</code> since the mae is higher. Let’s plot our <code class="language-plaintext highlighter-rouge">model_1</code> predictions so we can visualize them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Let's plot our model 1 predictions
</span><span class="n">offset</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="c1"># Account for the test_window offset and index into test_labels to ensure correct plotting
</span><span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span> <span class="c1"># start at the -556 index and include all going back
</span>                 <span class="n">values</span><span class="o">=</span><span class="n">test_labels</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test Data</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">model_1_preds</span><span class="p">,</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">model_1_preds</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/graph5.png" alt="" /></p>

<h2 id="model-2-dense-window--30-horizon--1">Model 2: Dense (window = 30, horizon = 1)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># predict one step at a time (one day of Bitcoin prices)
</span><span class="n">WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">30</span> <span class="c1"># use 30 timesteps in past
</span>
<span class="c1"># Make windowed data with appropriate horizon and window sizes
</span><span class="n">full_windows</span><span class="p">,</span> <span class="n">full_labels</span> <span class="o">=</span> <span class="nf">make_windows</span><span class="p">(</span><span class="n">prices</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">)</span>

<span class="c1"># Make train and testing windows
</span><span class="n">train_windows</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="nf">make_train_test_splits</span><span class="p">(</span><span class="n">windows</span><span class="o">=</span><span class="n">full_windows</span><span class="p">,</span>
                                                                                <span class="n">labels</span><span class="o">=</span><span class="n">full_labels</span><span class="p">,</span>
                                                                                <span class="n">test_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1"># Set random seed
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 1. Create model 2
</span><span class="n">model_2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
  <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
  <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_2_dense</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Compile the model
</span><span class="n">model_2</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">())</span>

<span class="c1"># 3. Fit the model
</span><span class="n">history_2</span> <span class="o">=</span> <span class="n">model_2</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_windows</span><span class="p">,</span>
                        <span class="n">train_labels</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
                        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_2</span><span class="p">.</span><span class="n">name</span><span class="p">)])</span>

<span class="c1"># Evaluate model 2 on test data
</span><span class="n">model_2</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 2ms/step - loss: 604.7626
604.7626342773438
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load in the best performing model
</span><span class="n">model_2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/model_experiments/model_2_dense/</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model_2</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>8/18 [==============================] - 0s 2ms/step - loss: 604.7626
604.7626342773438
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get forecast predictions
</span><span class="n">model_2_preds</span> <span class="o">=</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">model_2</span><span class="p">,</span>
                           <span class="n">input_data</span><span class="o">=</span><span class="n">test_windows</span><span class="p">)</span>

<span class="n">model_2_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_labels</span><span class="p">),</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_2_preds</span><span class="p">)</span>
<span class="n">model_2_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 604.7626,
 'mse': 1228286.1,
 'rmse': 1108.2808,
 'mape': 2.7903318,
 'mase': 1.0571309}
</code></pre></div></div>

<p>So <code class="language-plaintext highlighter-rouge">model_2</code> with a window size of 30 did not perform better since it was not able to beat the metrics of <code class="language-plaintext highlighter-rouge">model_1</code> which were the following:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 573.91125,
 'mse': 1186394.6,
 'rmse': 1089.2174,
 'mape': 2.5553186,
 'mase': 1.0082031}
</code></pre></div></div>

<p>Regardless, let’s plot the predictions of <code class="language-plaintext highlighter-rouge">model_2</code> to visualize them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">offset</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="c1"># Account for test_window when plotting
</span><span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">test_labels</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test Data</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">model_2_preds</span><span class="p">,</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">model_2_preds</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<p><img src="/images/bitcoin-images/graph6.png" alt="" /></p>

<h2 id="model-3-dense-window--30-horizon--7">Model 3: Dense (window = 30, horizon = 7)</h2>

<p>This time, we’ll be changing our horizon since from 1 to 7.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Change horizion and window_size parameters
</span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">30</span>

<span class="c1"># Create new windowed and label data
</span><span class="n">full_windows</span><span class="p">,</span> <span class="n">full_labels</span> <span class="o">=</span> <span class="nf">make_windows</span><span class="p">(</span><span class="n">prices</span><span class="p">,</span>
                                         <span class="n">window_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">,</span>
                                         <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">)</span>
<span class="c1"># Create new training data
</span><span class="n">train_windows</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="nf">make_train_test_splits</span><span class="p">(</span><span class="n">windows</span><span class="o">=</span><span class="n">full_windows</span><span class="p">,</span>
                                                                                <span class="n">labels</span><span class="o">=</span><span class="n">full_labels</span><span class="p">,</span>
                                                                                <span class="n">test_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Set random seed
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 1. Create model (same as model_1 except with different data input and output sizes)
</span><span class="n">model_3</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_3_dense</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Compile the model
</span><span class="n">model_3</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">())</span>

<span class="c1"># 3. Fit the model
</span><span class="n">history_3</span> <span class="o">=</span> <span class="n">model_3</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_windows</span><span class="p">,</span>
                        <span class="n">train_labels</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
                        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">model_3</span><span class="p">.</span><span class="n">name</span><span class="p">)])</span>

<span class="c1"># Evaluate model_3 on test data
</span><span class="n">model_3</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 2ms/step - loss: 1307.3239
1307.3238525390625
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load best version of model_3 and evaluate
</span><span class="n">model_3</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/model_experiments/model_3_dense/</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model_3</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 2ms/step - loss: 1242.7325
1242.7325439453125
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions with model_3
</span><span class="n">model_3_preds</span> <span class="o">=</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">model_3</span><span class="p">,</span>
                           <span class="n">input_data</span><span class="o">=</span><span class="n">test_windows</span><span class="p">)</span>
<span class="n">model_3_preds</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 2ms/step
&lt;tf.Tensor: shape=(5, 7), dtype=float32, numpy=
array([[9099.293, 9423.219, 9374.475, 9519.49 , 9581.897, 9383.432,
        9382.063],
       [8672.523, 8950.252, 9003.902, 9353.934, 9167.192, 8950.88 ,
        9005.712],
       [8529.572, 8770.096, 8716.261, 9261.693, 9052.481, 8982.425,
        9009.464],
       [8791.131, 9219.828, 9096.871, 9351.441, 9099.24 , 9226.614,
        9248.421],
       [8745.559, 9092.369, 8924.894, 9175.325, 9068.817, 9204.964,
        8877.882]], dtype=float32)&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Evaluate model_3 results
</span><span class="n">model_3_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_labels</span><span class="p">),</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_3_preds</span><span class="p">)</span>
<span class="n">model_3_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': array([ 601.6235  ,  336.93024 ,  369.2108  ,  521.055   ,  462.86328 ,
         525.67755 ,  572.0678  ,  501.66147 ,  472.31174 ,  597.5306  ,
         ........
         8.444713  ,  5.3952093 ,  3.1853058 ,  5.151429  ,  6.3232794 ,
        10.5625105 ,  6.168468  ,  2.5595644 ,  2.6729555 ,  4.013597  ,
         2.6416135 ,  3.1000364 ,  2.1299312 ,  2.3929665 ,  4.0625553 ,
         4.0429707 ,  4.3719726 ,  7.224757  , 12.552433  , 15.986694  ,
        18.703417  ], dtype=float32),
 'mase': 2.211373}     
</code></pre></div></div>

<p>As you can see there is a shape mismatch in our <code class="language-plaintext highlighter-rouge">model_3_results</code> since <code class="language-plaintext highlighter-rouge">model_3</code> has an output of 7 now instead of 1 since we set our <code class="language-plaintext highlighter-rouge">HORIZON</code> parameter to 7. In order to fix this, we need to fix our method that evaluates our model.</p>

<h2 id="make-our-evaluation-function-work-for-larger-horizons">Make our evaluation function work for larger horizons.</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a function to take in model predictions and truth values and return evaluation metics
</span><span class="k">def</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Return a dictionary of evaluation metrics
  </span><span class="sh">"""</span>
  <span class="c1"># Make sure float32 dtype (for metric calculations)
</span>  <span class="n">y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

  <span class="c1"># Calculate metrics
</span>  <span class="n">mae</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
  <span class="n">mse</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
  <span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
  <span class="n">mape</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
  <span class="n">mase</span> <span class="o">=</span> <span class="nf">mean_absolute_scaled_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

  <span class="c1"># Account for different sized metrics (for longer horizons, we want to reduce metrics to a single value)
</span>  <span class="k">if</span> <span class="n">mae</span><span class="p">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">mae</span><span class="p">)</span> <span class="c1"># computes the mean along all axis and condenses it down to a scalar
</span>                              <span class="c1"># to properly calculate it along our metrics and now we repeat for rest
</span>    <span class="n">mse</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">rmse</span><span class="p">)</span>
    <span class="n">mape</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">mape</span><span class="p">)</span>
    <span class="n">mase</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">mase</span><span class="p">)</span>

  <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">:</span> <span class="n">mae</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="p">:</span> <span class="n">mse</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">rmse</span><span class="sh">"</span><span class="p">:</span> <span class="n">rmse</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">mape</span><span class="sh">"</span><span class="p">:</span> <span class="n">mape</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span>
             <span class="sh">"</span><span class="s">mase</span><span class="sh">"</span><span class="p">:</span> <span class="n">mase</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()}</span>

  <span class="k">return</span> <span class="n">metrics</span>

<span class="c1"># Get model_3 results aggregated to single values
</span><span class="n">model_3_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_labels</span><span class="p">),</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_3_preds</span><span class="p">)</span>
<span class="n">model_3_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 1242.7323,
 'mse': 5326531.0,
 'rmse': 1431.5243,
 'mape': 5.6437564,
 'mase': 2.211373}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print results for model_2
</span><span class="n">model_2_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 604.7626,
 'mse': 1228286.1,
 'rmse': 1108.2808,
 'mape': 2.7903318,
 'mase': 1.0571309}
</code></pre></div></div>

<p>Now we can properly view <code class="language-plaintext highlighter-rouge">model_3_results</code> and its mae is worse than <code class="language-plaintext highlighter-rouge">model_2</code> however, we need to keep in mind that <code class="language-plaintext highlighter-rouge">model_3</code> is predicing on a larger horizon of 7.</p>

<p>What this means in terms of our Bitcoin data is that <code class="language-plaintext highlighter-rouge">model_3</code> trying to predict the price of Bitcoin for the next 7 days while <code class="language-plaintext highlighter-rouge">model_2</code> was only predicting the next day.</p>

<p>The further we try to predict the future, the more errors there will be.</p>

<p>With that being said, let’s go ahead and visualize <code class="language-plaintext highlighter-rouge">model_3</code> predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">offset</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">test_labels</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test Data</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">model_3_preds</span><span class="p">,</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">model_3_preds</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/graph7.png" alt="" /></p>

<p>Since our plot looks a little funky, we need to aggregate our <code class="language-plaintext highlighter-rouge">model_3_preds</code> in order to plot this properly. However, in the process of condensing <code class="language-plaintext highlighter-rouge">model_3_preds</code>, we will lose some information since these predictions were across 7 days.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">offset</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">test_labels</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test Data</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># This time aggregate model_3_preds by using tf.reduce_mean()
</span><span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">test_windows</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">model_3_preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">model_3_preds</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/graph8.png" alt="" /></p>

<h2 id="which-of-the-following-of-our-models-is-performing-the-best-so-far">Which of the following of our models is performing the best so far?</h2>

<p>So we’ve trained a few models, now let’s compare them and see how they’ve gone.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">naive</span><span class="sh">"</span><span class="p">:</span> <span class="n">naive_results</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">],</span>
              <span class="sh">"</span><span class="s">horizon_1_window_7</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_1_results</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">],</span>
              <span class="sh">"</span><span class="s">horizion_1_window_30</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_2_results</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">],</span>
              <span class="sh">"</span><span class="s">horizon_7_window_30</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_3_results</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">]},</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">]).</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">bar</span><span class="sh">"</span><span class="p">);</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/graph9.png" alt="" /></p>

<p>From the graph, the naive results have performed the best since it has the lowest mae. The naive results have performed the best due to the presence of autocorrelation in our data.</p>

<p>Autocorrelation, in the context of predicting Bitcoin prices, means that the price of Bitcoin today can give you clues about what its price might be tomorrow or in the future. If Bitcoin prices have high autocorrelation, it suggests that past prices are a good indicator of future prices.</p>

<h2 id="model-4-conv1d">Model 4: Conv1D</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># predict next day of Bitcoin prices
</span><span class="n">WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">7</span> <span class="c1"># use previous week worth data
</span>
<span class="c1"># Create windowed data
</span><span class="n">full_windows</span><span class="p">,</span> <span class="n">full_labels</span> <span class="o">=</span> <span class="nf">make_windows</span><span class="p">(</span><span class="n">prices</span><span class="p">,</span>
                                         <span class="n">window_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">,</span>
                                         <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">)</span>

<span class="c1"># Create train/test sets
</span><span class="n">train_windows</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="nf">make_train_test_splits</span><span class="p">(</span><span class="n">full_windows</span><span class="p">,</span> <span class="n">full_labels</span><span class="p">)</span>
</code></pre></div></div>

<p>To use the Conv1D layer, We need an input shape of: <code class="language-plaintext highlighter-rouge">(batch_size, timesteps, input_dim)</code>.</p>

<p>However, our data is not in that shape yet.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">expand_dims_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># add an extra dimension for `input_dim`
</span>
<span class="c1"># Test out our lambda layer
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Original shape: </span><span class="si">{</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># (WINDOW_SIZE)
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Expanded shape: </span><span class="si">{</span><span class="nf">expand_dims_layer</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Original values with expanded shape:</span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="nf">expand_dims_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original shape: (7,)
Expanded shape: (7, 1)
Original values with expanded shape:
 [[123.65499]
 [125.455  ]
 [108.58483]
 [118.67466]
 [121.33866]
 [120.65533]
 [121.795  ]]
</code></pre></div></div>

<p>From this, we need to use a lambda layer in order for our model to utilize a Conv1D layer.</p>

<p><img src="/images/bitcoin-images/nbeats_layer.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set random seed
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 1. Create Conv1D model
</span><span class="n">model_4</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                  <span class="n">kernel_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">,</span>
                  <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">causal</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># causal padding is good for temporal data
</span>                  <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_4_conv1D</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Compile the model
</span><span class="n">model_4</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">())</span>

<span class="c1"># 3. Fit the model
</span><span class="n">history_4</span> <span class="o">=</span> <span class="n">model_4</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_windows</span><span class="p">,</span>
                        <span class="n">train_labels</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
                        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_4</span><span class="p">.</span><span class="n">name</span><span class="p">)])</span>

<span class="c1"># Evaluate model
</span><span class="n">model_4</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 11ms/step - loss: 657.5205
657.5205078125
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load back in best performing Conv1D and re-evaluate
</span><span class="n">model_4</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/model_experiments/model_4_conv1D/</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model_4</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 5ms/step - loss: 572.9781
572.9781494140625
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions
</span><span class="n">model_4_preds</span> <span class="o">=</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">model_4</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">)</span>

<span class="c1"># Evaluate predictions
</span><span class="n">model_4_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_labels</span><span class="p">),</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_4_preds</span><span class="p">)</span>
<span class="n">model_4_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 572.9782,
 'mse': 1188977.0,
 'rmse': 1090.4022,
 'mape': 2.5686033,
 'mase': 1.006564}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print resuts for model_1
</span><span class="n">model_1_results</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 573.91125,
 'mse': 1186394.6,
 'rmse': 1089.2174,
 'mape': 2.5553186,
 'mase': 1.0082031}
</code></pre></div></div>

<p>It looks like <code class="language-plaintext highlighter-rouge">model_4</code> slightly beat <code class="language-plaintext highlighter-rouge">model_1</code> in mae but still hasn’t beat the naive forecast.</p>

<h2 id="model-5-rnn-lstm">Model 5: RNN (LSTM)</h2>

<p>Let’s build an RNN model for our time series data.</p>

<p>We’ll use the same data we created previously.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set random seed
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 1. Build an LSTM model with Functional API
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">WINDOW_SIZE</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model_5</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                         <span class="n">outputs</span><span class="o">=</span><span class="n">output</span><span class="p">,</span>
                         <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_5_LSTM</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Compile the model
</span><span class="n">model_5</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">())</span>

<span class="c1"># 3. Fit the model
</span><span class="n">history_5</span> <span class="o">=</span> <span class="n">model_5</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_windows</span><span class="p">,</span>
                        <span class="n">train_labels</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
                        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_5</span><span class="p">.</span><span class="n">name</span><span class="p">)])</span>

<span class="c1"># Load in best version of model 5 and evaluate on the test data
</span><span class="n">model_5</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/model_experiments/model_5_LSTM</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model_5</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_windows</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 2ms/step - loss: 589.7722
589.7721557617188
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions with our LSTM model
</span><span class="n">model_5_preds</span> <span class="o">=</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">model_5</span><span class="p">,</span> <span class="n">test_windows</span><span class="p">)</span>

<span class="c1"># Evaluate model 5 preds
</span><span class="n">model_5_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">test_labels</span><span class="p">),</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_5_preds</span><span class="p">)</span>
<span class="n">model_5_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 589.7721,
 'mse': 1253439.4,
 'rmse': 1119.571,
 'mape': 2.6584451,
 'mase': 1.0360662}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print model_1 results
</span><span class="n">model_1_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output:</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 573.91125,
 'mse': 1186394.6,
 'rmse': 1089.2174,
 'mape': 2.5553186,
 'mase': 1.0082031}
</code></pre></div></div>

<p>Our LSTM model <code class="language-plaintext highlighter-rouge">(model_5)</code> is still not performing better than our simple dense model <code class="language-plaintext highlighter-rouge">(model_1)</code>. This simply iterates that building a more complex model does not always guarantee better results.</p>

<h2 id="make-a-multivariate-time-series-dataset">Make a multivariate time series dataset</h2>

<p>Before we add a feature to our time series, what is a feature we can use?</p>

<p>What’s a better feature to use?</p>

<p>How about the bitcoin halving <a href="https://www.cmcmarkets.com/en/learn-cryptocurrencies/bitcoin-halving">events</a>?</p>

<p>We are essentially going to utilize the data from the source above from this following table:</p>

<p><img src="/images/bitcoin-images/block.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Let's make a multivariate time series
</span><span class="n">bitcoin_prices</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	    
Date	        Price
2013-10-01	123.65499
2013-10-02	125.45500
2013-10-03	108.58483
2013-10-04	118.67466
2013-10-05	121.33866
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Let's add the bitcoin halving events to our dataset
</span><span class="n">block_reward_1</span> <span class="o">=</span> <span class="mi">50</span> <span class="c1"># 3 January 2009 (2009-01-03) - this block reward isn't in our dataset (it starts from 01 October 2013)
</span><span class="n">block_reward_2</span> <span class="o">=</span> <span class="mi">25</span> <span class="c1"># 28 November 2012
</span><span class="n">block_reward_3</span> <span class="o">=</span> <span class="mf">12.5</span> <span class="c1"># 9 July 2016
</span><span class="n">block_reward_4</span> <span class="o">=</span> <span class="mf">6.25</span> <span class="c1"># 11 May 2020
</span>
<span class="c1"># Block reward dates (datetime form of the above date stamps)
</span><span class="n">block_reward_2_datetime</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">datetime64</span><span class="p">(</span><span class="sh">"</span><span class="s">2012-11-28</span><span class="sh">"</span><span class="p">)</span>
<span class="n">block_reward_3_datetime</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">datetime64</span><span class="p">(</span><span class="sh">"</span><span class="s">2016-07-09</span><span class="sh">"</span><span class="p">)</span>
<span class="n">block_reward_4_datetime</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">datetime64</span><span class="p">(</span><span class="sh">"</span><span class="s">2020-05-11</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Create date ranges of where specific block_reward values should be
</span><span class="n">block_reward_2_days</span> <span class="o">=</span> <span class="p">(</span><span class="n">block_reward_3_datetime</span> <span class="o">-</span> <span class="n">bitcoin_prices</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="n">days</span>
<span class="n">block_reward_3_days</span> <span class="o">=</span> <span class="p">(</span><span class="n">block_reward_4_datetime</span> <span class="o">-</span> <span class="n">bitcoin_prices</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="n">days</span>
<span class="n">block_reward_2_days</span><span class="p">,</span> <span class="n">block_reward_3_days</span>

<span class="c1"># Add in a block_reward column
</span><span class="n">bitcoin_prices_block</span> <span class="o">=</span> <span class="n">bitcoin_prices</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">bitcoin_prices_block</span><span class="p">[</span><span class="sh">"</span><span class="s">block_reward</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

<span class="c1"># Add in block_reward values as a feature to our dataframe
</span><span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">block_reward_2_days</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">block_reward_2</span> <span class="c1"># -1 get's last column
</span><span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">block_reward_2_days</span><span class="p">:</span><span class="n">block_reward_3_days</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">block_reward_3</span>
<span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">block_reward_3_days</span><span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">block_reward_4</span>

<span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Date	      Price	   	 block_reward
2013-10-01	123.65499	 25
2013-10-02	125.45500	 25
2013-10-03	108.58483	 25
2013-10-04	118.67466	 25
2013-10-05	121.33866	 25
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	
Date		    Price         block_reward
2021-05-14	49764.132082	6.25
2021-05-15	50032.693137	6.25
2021-05-16	47885.625255	6.25
2021-05-17	45604.615754	6.25
2021-05-18	43144.471291	6.25
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot the block reward vs price over time
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">minmax_scale</span>
<span class="n">scaled_price_block_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="nf">minmax_scale</span><span class="p">(</span><span class="n">bitcoin_prices_block</span><span class="p">[[</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">block_reward</span><span class="sh">"</span><span class="p">]]),</span> <span class="c1"># scale prices down so we can properly see the block reward on graph
</span>                                     <span class="n">columns</span><span class="o">=</span><span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
                                     <span class="n">index</span><span class="o">=</span><span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">scaled_price_block_df</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">));</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/graph10.png" alt="" /></p>

<h2 id="making-a-windowed-dataset-with-pandas">Making a windowed dataset with pandas</h2>

<p>Previously, we’ve turned our univariate time series into a windowed dataset using the helper functions above.</p>

<p>However, since we’ve now got multivariate data, these functions won’t work.</p>

<p>Not to worry, we can use the <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html">pandas.DataFrame.shift()</a> method to window our multivariate data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Setup dataset hyperparameters
</span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">7</span>

<span class="c1"># Make a copy of the Bitcoin historical data with block reward feature
</span><span class="n">bitcoin_prices_windowed</span> <span class="o">=</span> <span class="n">bitcoin_prices_block</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>

<span class="c1"># Add windowed columns
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">WINDOW_SIZE</span><span class="p">):</span> <span class="c1"># shift values for each step in WINDOW_SIZE
</span>  <span class="n">bitcoin_prices_windowed</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">Price+</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">bitcoin_prices_windowed</span><span class="p">[</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">].</span><span class="nf">shift</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bitcoin_prices_windowed</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/df-2.png" alt="" /></p>

<p>What we’ve done is we created a way to window our dataset directly from a pandas dataframe.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 1, 2, 3, 4, 5, 6, block_reward] -&gt; [7]
[1, 2, 3, 4, 5, 6, 7, block_reward] -&gt; [8]
[2, 3, 4, 5, 6, 7, 8, block_reward] -&gt; [9]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create X (windows) and y (horizons) features
</span><span class="n">X</span> <span class="o">=</span> <span class="n">bitcoin_prices_windowed</span><span class="p">.</span><span class="nf">dropna</span><span class="p">().</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># TensorFlow needs data in float32
</span><span class="n">y</span> <span class="o">=</span> <span class="n">bitcoin_prices_windowed</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()[</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/df-3.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Date
2013-10-08    123.032997
2013-10-09    124.049004
2013-10-10    125.961159
2013-10-11    125.279663
2013-10-12    125.927498
Name: Price, dtype: float32
</code></pre></div></div>

<h2 id="model-6-dense-multivariate-time-series">Model 6: Dense (multivariate time series)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set random seed
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 1. Create model
</span><span class="n">model_6</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_6_dense_multivariate</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Compile the model
</span><span class="n">model_6</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># 3. Fit the model
</span><span class="n">model_6</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_6</span><span class="p">.</span><span class="n">name</span><span class="p">)])</span>

<span class="c1"># Evaluate multivarte model
</span><span class="n">model_6</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 3ms/step - loss: 565.8015 - mae: 565.8015
[565.8014526367188, 565.8014526367188]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions with multivariate model
</span><span class="n">model_6_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">model_6</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>

<span class="c1"># Evalaute predictions to get evaluation metrics
</span><span class="n">model_6_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_6_preds</span><span class="p">)</span>
<span class="n">model_6_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 565.8015,
 'mse': 1158762.9,
 'rmse': 1076.4585,
 'mape': 2.5594444,
 'mase': 0.99395657}
</code></pre></div></div>

<p>So our naive_results were the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Naive Results:
{'mae': 567.9802,
 'mse': 1147547.0,
 'rmse': 1071.2362,
 'mape': 2.516525,
 'mase': 0.99957}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">model_6</code> was able to beat our naive results in mae.</p>

<h2 id="model-7-n-beats-algorithm">Model 7: N-BEATS Algorithm</h2>

<p>Let’s now try to build the biggest time series forecasting model we’ve built so far.</p>

<p>More specifically, we’re going to be replicating the algorithm in Figure 1 from the following <a href="https://arxiv.org/pdf/1905.10437.pdf">paper</a>.</p>

<p><img src="/images/bitcoin-images/figure-2.png" alt="" /></p>

<p><strong>Source:</strong> Figure 1 (Section 3.1) N-BEATS paper</p>

<h3 id="building-and-testing-the-n-beats-block-layer">Building and testing the N-BEATS Block Layer</h3>

<p>Because the N-BEATS block layer does not exist in TensorFlow, we’ve got to create it.</p>

<p>To create custom layers and models in TensorFlow, we can use <a href="https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing">subclassing</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create NBeatsBlock custom layer
</span><span class="k">class</span> <span class="nc">NBeatsBlock</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="c1"># the constructor takes all the hyperparameters for the layer
</span>               <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">theta_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">horizon</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">n_neurons</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="c1"># the **kwargs argument takes care of all the arguments for the parent class (input_shape, trainable, name)
</span>    <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="c1"># init the parent keras layer class, allowing this custom layer to inherit all the functionalities and properties of a standard keras layer
</span>    <span class="n">self</span><span class="p">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
    <span class="n">self</span><span class="p">.</span><span class="n">theta_size</span> <span class="o">=</span> <span class="n">theta_size</span>
    <span class="n">self</span><span class="p">.</span><span class="n">horizon</span> <span class="o">=</span> <span class="n">horizon</span>
    <span class="n">self</span><span class="p">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
    <span class="n">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>

    <span class="c1"># Block contains stack of 4 fully connected layers each has ReLU activation (this is our fully connected stack)
</span>    <span class="n">self</span><span class="p">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>

    <span class="c1"># Output of block is a theta layer with linear activation
</span>    <span class="n">self</span><span class="p">.</span><span class="n">theta_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">theta_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">theta</span><span class="sh">"</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span> <span class="c1"># the call method is what runs when the layer is called
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span> <span class="c1"># x is going to continue to be updated as it passses through each layer in the stack
</span>    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden</span><span class="p">:</span> <span class="c1"># pass inputs through each hidden layer
</span>      <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">theta_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Output the backcast and the forecast from theta
</span>    <span class="c1"># The backcast takes the first part of the theta vector, up to self.input_size, which represents the model's understanding or reconstruction of the input data (i.e., the past).
</span>    <span class="c1"># The forecast takes the last part of the theta vector, the last self.horizon elements, which represents the model's prediction for the future.
</span>    <span class="n">backcast</span><span class="p">,</span> <span class="n">forecast</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[:,</span> <span class="p">:</span><span class="n">self</span><span class="p">.</span><span class="n">input_size</span><span class="p">],</span> <span class="n">theta</span><span class="p">[:,</span> <span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">horizon</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">backcast</span><span class="p">,</span> <span class="n">forecast</span>
</code></pre></div></div>

<p>Let’s test our NbeatsBlock class.</p>

<p>To do so, we’ll make some dummy inputs and outputs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set up dummy NbeatsBlock layer to represent inputs and outputs
</span><span class="n">dummy_nbeats_block_layer</span> <span class="o">=</span> <span class="nc">NBeatsBlock</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">,</span>
                                       <span class="n">theta_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="o">+</span><span class="n">HORIZON</span><span class="p">,</span> <span class="c1">#backcast + forecast
</span>                                       <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">,</span>
                                       <span class="n">n_neurons</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                                       <span class="n">n_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Create dummy inputs (have to be same size as input_size)
</span><span class="n">dummy_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="n">WINDOW_SIZE</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># input shape to the model has to reflect dense layer input requirements
</span><span class="n">dummy_inputs</span> 
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: &lt;tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 2, 3, 4, 5, 6, 7]], dtype=int32)&gt;</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pass dummy inputs to dummy NbeatsBlock layer
</span><span class="n">backcast</span><span class="p">,</span> <span class="n">forecast</span> <span class="o">=</span> <span class="nf">dummy_nbeats_block_layer</span><span class="p">(</span><span class="n">dummy_inputs</span><span class="p">)</span>
<span class="c1"># These are the activation outputs of the theta layer (they'll be random due to no training of the model)
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Backcast: </span><span class="si">{</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">backcast</span><span class="p">.</span><span class="nf">numpy</span><span class="p">())</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Forecast: </span><span class="si">{</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">forecast</span><span class="p">.</span><span class="nf">numpy</span><span class="p">())</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Backcast: [-0.38389418  0.35329175 -0.0333121  -0.11072142 -0.13326252 -0.4649477
  0.45009223]
Forecast: -0.21032658219337463
</code></pre></div></div>

<h3 id="preparing-data-for-the-n-beats-algorithm-using-tfdata">Preparing data for the N-BEATS algorithm using <code class="language-plaintext highlighter-rouge">tf.data</code></h3>

<p>To make our input data load as fast as possible we’re going to be adhering to the performant data pipeline steps in the <a href="https://www.tensorflow.org/guide/data_performance">tf.data guide</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">7</span>

<span class="c1"># Create N_BEATS data inputs (N-BEATS works with univariate time series)
</span><span class="n">bitcoin_prices</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Date	      Price
2013-10-01	123.65499
2013-10-02	125.45500
2013-10-03	108.58483
2013-10-04	118.67466
2013-10-05	121.33866
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Add windowed columns
</span><span class="n">bitcoin_prices_nbeats</span> <span class="o">=</span> <span class="n">bitcoin_prices</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range </span><span class="p">(</span><span class="n">WINDOW_SIZE</span><span class="p">):</span>
  <span class="n">bitcoin_prices_nbeats</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="s">Price+</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">bitcoin_prices_nbeats</span><span class="p">[</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">].</span><span class="nf">shift</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bitcoin_prices_nbeats</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/df-4.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make features and labels
</span><span class="n">X</span> <span class="o">=</span> <span class="n">bitcoin_prices_nbeats</span><span class="p">.</span><span class="nf">dropna</span><span class="p">().</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bitcoin_prices_nbeats</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()[</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># Make train and test sets
</span><span class="n">split_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">split_size</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_size</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">split_size</span><span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_size</span><span class="p">:]</span>

<span class="c1"># Time to make our dataset performant using the tf.data API
</span><span class="n">train_features_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">train_labels_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">test_features_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_labels_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>

<span class="c1"># Combine labels and features by zipping together -&gt; (feature, labels)
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">zip</span><span class="p">((</span><span class="n">train_features_dataset</span><span class="p">,</span> <span class="n">train_labels_dataset</span><span class="p">))</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">zip</span><span class="p">((</span><span class="n">test_features_dataset</span><span class="p">,</span> <span class="n">test_labels_dataset</span><span class="p">))</span>

<span class="c1"># Batch and prefetch
</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">).</span><span class="nf">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">).</span><span class="nf">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>

<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))&gt;,
 &lt;_PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))&gt;)
</code></pre></div></div>

<h3 id="setting-up-hyperparameters-for-n-beats-algorithm">Setting up hyperparameters for N-BEATS Algorithm</h3>

<p>The N_BEATS algorithm has a fair few numbers of parameters, many of which can be found in Table 18 <a href="https://arxiv.org/pdf/1905.10437.pdf">here</a>:</p>

<p><img src="/images/bitcoin-images/table-18.png" alt="" /></p>

<p><strong>Source:</strong> Table 18 (Section C.5) N-BEATS paper</p>

<p>We will use their values for the parameters below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Values from N_BEATS paper
</span><span class="n">N_EPOCHS</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">N_NEURONS</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">N_LAYERS</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">N_STACKS</span> <span class="o">=</span> <span class="mi">30</span>

<span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="n">WINDOW_SIZE</span> <span class="o">*</span> <span class="n">HORIZON</span>
<span class="n">THETA_SIZE</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span> <span class="o">+</span> <span class="n">HORIZON</span>

<span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">THETA_SIZE</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: (7, 8)</code></p>

<h3 id="getting-ready-for-the-residual-connections">Getting ready for the residual connections</h3>

<p>Before we can create our N-BEATS model, we need two layers for the residual connections (subtract and add).</p>

<p>The N-BEATS algorithm uses double residual stacking to help train its deeper architecture (section 3.2 of N-BEATS paper).</p>

<p>More information on residual connections <a href="https://en.wikipedia.org/wiki/Residual_neural_network">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make tensors
</span><span class="n">tensor_1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span>
<span class="n">tensor_2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Subtract
</span><span class="n">subtracted</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nf">subtract</span><span class="p">([</span><span class="n">tensor_1</span><span class="p">,</span> <span class="n">tensor_2</span><span class="p">])</span>

<span class="c1"># Add
</span><span class="n">added</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nf">add</span><span class="p">([</span><span class="n">tensor_1</span><span class="p">,</span> <span class="n">tensor_2</span><span class="p">])</span>

<span class="c1"># Get ouputs
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Input tensors: </span><span class="si">{</span><span class="n">tensor_1</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span><span class="si">}</span><span class="s"> &amp; </span><span class="si">{</span><span class="n">tensor_2</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Subtracted: </span><span class="si">{</span><span class="n">subtracted</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Added: </span><span class="si">{</span><span class="n">added</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input tensors: [10 11 12 13 14 15 16 17 18 19] &amp; [0 1 2 3 4 5 6 7 8 9]
Subtracted: [10 10 10 10 10 10 10 10 10 10]
Added: [10 12 14 16 18 20 22 24 26 28]
</code></pre></div></div>

<h3 id="building-compiling-and-fitting-the-n-beats-algorithm">Building, compiling, and fitting the N-BEATS algorithm</h3>

<ol>
  <li>Set up an instance of the N-BEATS block layer using <code class="language-plaintext highlighter-rouge">NBeatsBlock</code> (that’ll be the initial block used for the network, and then the rest will be created as part of stacks).</li>
  <li>Create an input layer for the N-BEATS stack (we’ll be using the Keras Functional API).</li>
  <li>Make the initial forecast and forecasts for the model with the layer created in (1).</li>
  <li>Use a for loop to create stacks of block layers.</li>
  <li>Use the <code class="language-plaintext highlighter-rouge">NBeatsBlock</code> class within the for loop in (4) to create blocks that return backcasts and block-level forecasts.</li>
  <li>Create the double residual stacking using subtract and add layers.</li>
  <li>Put the model inputs and outputs together using <code class="language-plaintext highlighter-rouge">tf.keras.Model()</code>.</li>
  <li>Compile the model with MAE loss (the paper uses multiple losses but we’ll use MAE to keep it in line with our models) and Adam optimizer with default setting as per section 5.2 of N-BEATS paper.</li>
  <li>Fit the N-BEATS model for 5000 epochs and since it’s fitting for so many epochs, we’ll use a couple of callbacks:
    <ul>
      <li>Early Stopping - because the model will be training for so long, we’ll stop it early if it stops improving.</li>
      <li>Reduce LR on Plateau - if a model stops improving, try lowering and learning to reduce the amount it updates its weights each time (take smaller steps towards best performance)</li>
    </ul>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="c1"># Set seed
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 1. Setup an instance of the NBeatBlock
</span><span class="n">nbeats_block_layer</span> <span class="o">=</span> <span class="nc">NBeatsBlock</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">INPUT_SIZE</span><span class="p">,</span>
                                 <span class="n">theta_size</span><span class="o">=</span><span class="n">THETA_SIZE</span><span class="p">,</span>
                                 <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">,</span>
                                 <span class="n">n_neurons</span><span class="o">=</span><span class="n">N_NEURONS</span><span class="p">,</span>
                                 <span class="n">n_layers</span><span class="o">=</span><span class="n">N_LAYERS</span><span class="p">,</span>
                                 <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">InitialBlock</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Create input to stacks
</span><span class="n">stack_input</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">INPUT_SIZE</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">stack_input</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 3. Create initial backcast and forecast input (backwards prediction + horizon prediction)
</span><span class="n">backcast</span><span class="p">,</span> <span class="n">forecast</span> <span class="o">=</span> <span class="nf">nbeats_block_layer</span><span class="p">(</span><span class="n">stack_input</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nf">subtract</span><span class="p">([</span><span class="n">stack_input</span><span class="p">,</span> <span class="n">backcast</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">subtract_00</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 4. Create stacks of blocks
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">N_STACKS</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span> <span class="c1"># -1 since we already have an inital stack in step 3 and use _ since we only care about the indices
</span>
  <span class="c1"># 5. Use the NBeatsBlock to calculate the backcast as well as block forecast
</span>  <span class="n">backcast</span><span class="p">,</span> <span class="n">block_forecast</span> <span class="o">=</span> <span class="nc">NBeatsBlock</span><span class="p">(</span>
      <span class="n">input_size</span><span class="o">=</span><span class="n">INPUT_SIZE</span><span class="p">,</span>
      <span class="n">theta_size</span><span class="o">=</span><span class="n">THETA_SIZE</span><span class="p">,</span>
      <span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">,</span>
      <span class="n">n_neurons</span><span class="o">=</span><span class="n">N_NEURONS</span><span class="p">,</span>
      <span class="n">n_layers</span><span class="o">=</span><span class="n">N_LAYERS</span><span class="p">,</span>
      <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">NBeatsBlock_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span>
  <span class="p">)(</span><span class="n">residuals</span><span class="p">)</span> <span class="c1"># pass it in residuals (the backcast)
</span>
  <span class="c1"># 6. Create the double residual stacking
</span>  <span class="n">residuals</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nf">subtract</span><span class="p">([</span><span class="n">residuals</span><span class="p">,</span> <span class="n">backcast</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">subtract_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
  <span class="n">forecast</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nf">add</span><span class="p">([</span><span class="n">forecast</span><span class="p">,</span> <span class="n">block_forecast</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">add_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 7. Put the stack model together
</span><span class="n">model_7</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">stack_input</span><span class="p">,</span>
                         <span class="n">outputs</span><span class="o">=</span><span class="n">forecast</span><span class="p">,</span>
                         <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_7_N-BEATS</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 8. Compile with MAE loss and Adam optimizer
</span><span class="n">model_7</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks
</span><span class="n">model_7</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">N_EPOCHS</span><span class="p">,</span>
            <span class="n">validation_data</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1"># prevent large amounts of training outputs
</span>            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="sh">"</span><span class="s">val_loss</span><span class="sh">"</span><span class="p">,</span>
                                                        <span class="n">patience</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                                                        <span class="n">restore_best_weights</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
                      <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="sh">"</span><span class="s">val_loss</span><span class="sh">"</span><span class="p">,</span>
                                                           <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                                           <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 356: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 456: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
CPU times: user 2min 17s, sys: 3.54 s, total: 2min 20s
Wall time: 2min 43s
&lt;keras.src.callbacks.History at 0x780fd49c9330
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Evaluate N-Beats model on the test dataset
</span><span class="n">model_7</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1/1 [==============================] - 0s 25ms/step - loss: 565.6628 - mae: 565.6628 - mse: 1136878.1250
[565.662841796875, 565.662841796875, 1136878.125]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions with N-BEATS model
</span><span class="n">model_7_preds</span> <span class="o">=</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">model_7</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">)</span>

<span class="c1"># Evaluate N-BEATS model preds
</span><span class="n">model_7_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
                                 <span class="n">y_pred</span><span class="o">=</span><span class="n">model_7_preds</span><span class="p">)</span>
<span class="n">model_7_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 565.66284,
 'mse': 1136878.1,
 'rmse': 1066.2449,
 'mape': 2.6194174,
 'mase': 0.99371296}
</code></pre></div></div>

<p>Here are our metrics for a few of the models, we have compiled:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>naive_results: {'mae': 567.9802, 'mse': 1147547.0, 'rmse': 1071.2362, 'mape': 2.516525, 'mase': 0.99957}

model_1_results: {'mae': 573.91125, 'mse': 1186394.6, 'rmse': 1089.2174, 'mape': 2.5553186, 'mase': 1.0082031}

model_6_reslts{'mae': 565.8015, 'mse': 1158762.9, 'rmse': 1076.4585, 'mape': 2.5594444, 'mase': 0.99395657}

model_7_results{'mae': 565.66284, 'mse': 1136878.1, 'rmse': 1066.2449, 'mape': 2.6194174, 'mase': 0.99371296}
</code></pre></div></div>

<p>so <code class="language-plaintext highlighter-rouge">model_7</code> did beat all 3 models above, but it barely beat <code class="language-plaintext highlighter-rouge">model_6</code>.</p>

<p>This goes to show the power of smaller networks.  Not all larger models are better suited for certain types of data since we barely got an increase.</p>

<h3 id="plotting-the-n-beats-arhitecture-weve-created">Plotting the N-Beats arhitecture we’ve created</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot the N-BEATS model and inspect the architecture
</span><span class="kn">from</span> <span class="n">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
<span class="nf">plot_model</span><span class="p">(</span><span class="n">model_7</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/n-beats-architecture.png" alt="" /></p>

<p><strong>Note:</strong> To properly view this image, open the image in a new tab and zoom in to inspect it because this is a huge model.</p>

<p>This just shows that even if with an advanced model, it is not always the solution to our problems.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_model</span><span class="p">(</span><span class="n">model_1</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/model-1-architecture.png" alt="" /></p>

<p>The architecture for <code class="language-plaintext highlighter-rouge">model_1</code> is very simple compared to the architecture of <code class="language-plaintext highlighter-rouge">model_7.</code> Since <code class="language-plaintext highlighter-rouge">model_7</code> was not able to perform better than our naive results, let’s try to utilize ensemble learning.</p>

<h2 id="model-8-creating-an-ensemble-stacking-different-models-together">Model 8: Creating an ensemble (stacking different models together)</h2>

<p>An ensemble is like having a group of different experts working together to make better predictions or decisions for a shared goal. They combine their strengths to improve the outcome.</p>

<p>So we will  combine many <em>different</em> models to predict a common goal.</p>

<h3 id="constructing-and-fitting-an-ensemble-of-models-using-different-loss-functions">Constructing and fitting an ensemble of models (using different loss functions)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_ensemble_models</span><span class="p">(</span><span class="n">horizon</span><span class="o">=</span><span class="n">HORIZON</span><span class="p">,</span>
                        <span class="n">train_data</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                        <span class="n">test_data</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
                        <span class="n">num_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                        <span class="n">loss_fns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mape</span><span class="sh">"</span><span class="p">]):</span>
  <span class="sh">"""</span><span class="s">
  Returns a list of num_iter models each trained on MAE, MSE, and MAPE loss.

  For example, if num_iter=10, a list of 30 trained models will be returned.
  10 * len([</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="s">mape</span><span class="sh">"</span><span class="s">])
  </span><span class="sh">"""</span>
  <span class="c1"># Make empty list for trained ensemble models
</span>  <span class="n">ensemble_models</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># Create num_iter number of models per loss function
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iter</span><span class="p">):</span>
    <span class="c1"># Build and fit a new model with a different loss function
</span>    <span class="k">for</span> <span class="n">loss_function</span> <span class="ow">in</span> <span class="n">loss_fns</span><span class="p">:</span>
      <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Optimizing model by reducing: </span><span class="si">{</span><span class="n">loss_function</span><span class="si">}</span><span class="s"> for </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s"> epochs, model number: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

      <span class="c1"># Construct a simple model (similiar to model_1)
</span>      <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
          <span class="c1"># Initialize dense layers with normal distribution for estimating prediction intervals later on
</span>          <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="sh">"</span><span class="s">he_normal</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
          <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="sh">"</span><span class="s">he_normal</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
          <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">)</span>
      <span class="p">])</span>

      <span class="c1"># Compile simple model with current loss function
</span>      <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss_function</span><span class="p">,</span>
                    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(),</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mse</span><span class="sh">"</span><span class="p">])</span>

      <span class="c1"># Fit the current model
</span>      <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">validation_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="sh">"</span><span class="s">val_loss</span><span class="sh">"</span><span class="p">,</span>
                                                            <span class="n">patience</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                                                            <span class="n">restore_best_weights</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
                           <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="sh">"</span><span class="s">val_loss</span><span class="sh">"</span><span class="p">,</span>
                                                                <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                                                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span>
      <span class="c1"># Append fitted model to list of ensemble models
</span>      <span class="n">ensemble_models</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">ensemble_models</span>

<span class="o">%%</span><span class="n">time</span>
<span class="c1"># Get list of trained ensemble models
</span><span class="n">ensemble_models</span> <span class="o">=</span> <span class="nf">get_ensemble_models</span><span class="p">(</span><span class="n">num_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                      <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimizing model by reducing: mae for 1000 epochs, model number: 0

Epoch 349: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 896: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 996: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Optimizing model by reducing: mse for 1000 epochs, model number: 0

Epoch 769: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 869: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Optimizing model by reducing: mape for 1000 epochs, model number: 0

Epoch 203: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 324: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 424: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Optimizing model by reducing: mae for 1000 epochs, model number: 1

Epoch 506: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 606: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Optimizing model by reducing: mse for 1000 epochs, model number: 1

Epoch 994: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Optimizing model by reducing: mape for 1000 epochs, model number: 1

Epoch 123: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 498: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 598: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Optimizing model by reducing: mae for 1000 epochs, model number: 2

Epoch 485: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Optimizing model by reducing: mse for 1000 epochs, model number: 2

Epoch 377: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 477: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Optimizing model by reducing: mape for 1000 epochs, model number: 2

Epoch 182: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 298: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 398: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Optimizing model by reducing: mae for 1000 epochs, model number: 3

Epoch 306: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 733: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 833: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Optimizing model by reducing: mse for 1000 epochs, model number: 3

Epoch 456: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 556: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Optimizing model by reducing: mape for 1000 epochs, model number: 3

Epoch 155: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 859: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Optimizing model by reducing: mae for 1000 epochs, model number: 4
Optimizing model by reducing: mse for 1000 epochs, model number: 4

Epoch 166: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 266: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Optimizing model by reducing: mape for 1000 epochs, model number: 4

Epoch 189: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 555: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 655: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
CPU times: user 6min 28s, sys: 25.3 s, total: 6min 53s
Wall time: 8min 20s
</code></pre></div></div>

<h3 id="make-predictions-with-our-ensemble-model">Make predictions with our ensemble model</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a function which uses a list of trained models to make and returns a list of predictions
</span><span class="k">def</span> <span class="nf">make_ensemble_preds</span><span class="p">(</span><span class="n">ensemble_models</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">ensemble_preds</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">ensemble_models</span><span class="p">:</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">ensemble_preds</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">constant</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">ensemble_preds</span><span class="p">))</span>

<span class="c1"># Create a list of ensemble predictions
</span><span class="o">%%</span><span class="n">time</span>
<span class="n">ensemble_preds</span> <span class="o">=</span> <span class="nf">make_ensemble_preds</span><span class="p">(</span><span class="n">ensemble_models</span><span class="o">=</span><span class="n">ensemble_models</span><span class="p">,</span>
                                     <span class="n">data</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>
<span class="n">ensemble_preds</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1/1 [==============================] - 0s 103ms/step
1/1 [==============================] - 0s 36ms/step
WARNING:tensorflow:5 out of the last 22 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x780fb9691c60&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1/1 [==============================] - 0s 43ms/step
WARNING:tensorflow:6 out of the last 23 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x780fb9692200&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 49ms/step
1/1 [==============================] - 0s 44ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 46ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 40ms/step
CPU times: user 723 ms, sys: 26.2 ms, total: 750 ms
Wall time: 920 ms
&lt;tf.Tensor: shape=(15, 556), dtype=float32, numpy=
array([[ 8794.778 ,  8736.29  ,  9002.372 , ..., 50816.07  , 48777.586 ,
        46801.72  ],
       [ 8780.926 ,  8782.378 ,  9051.5205, ..., 49707.086 , 48328.438 ,
        45887.953 ],
       [ 8757.609 ,  8762.503 ,  9057.98  , ..., 50080.36  , 48873.926 ,
        46489.086 ],
       ...,
       [ 8713.883 ,  8696.286 ,  9018.408 , ..., 49438.92  , 48778.84  ,
        45288.473 ],
       [ 8718.306 ,  8827.489 ,  9065.84  , ..., 50348.074 , 47440.4   ,
        45822.406 ],
       [ 8796.017 ,  8778.755 ,  9069.521 , ..., 50396.266 , 48528.64  ,
        46270.938 ]], dtype=float32)&gt;
</code></pre></div></div>

<p>Our ensemble preds came out in multiple dimensions but to combine into <strong>point prediction</strong>, we can leverage the mean of all our predictions or the median.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">ensemble_median</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">median</span><span class="p">(</span><span class="n">ensemble_preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Evaluate ensemble model predictions with ensemble_median
</span><span class="n">ensemble_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
                                  <span class="n">y_pred</span><span class="o">=</span><span class="n">ensemble_median</span><span class="p">)</span>
<span class="n">ensemble_results</span>

</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 570.02594,
 'mse': 1153090.5,
 'rmse': 1073.8206,
 'mape': 2.583799,
 'mase': 1.0013777}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print model_7 results
</span><span class="n">model_7_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 565.66284,
 'mse': 1136878.1,
 'rmse': 1066.2449,
 'mape': 2.6194174,
 'mase': 0.99371296}
</code></pre></div></div>

<p>Our ensemble model was not able to beat <code class="language-plaintext highlighter-rouge">model_7</code> since the mae is higher.</p>

<h3 id="plotting-the-prediction-intervals-uncertainty-estimates-of-our-ensemble">Plotting the prediction intervals (uncertainty estimates) of our ensemble</h3>

<p>So far we’ve been making predictions with our models.</p>

<p>E.g. horizon = 1, our model predicts tomorrow’s price of Bitcoin will be $50,000 USD</p>

<p>Wouldn’t it be helpful if we knew a range of where that prediction came from?</p>

<p>Instead of $50,000 USD on the dot, how about $48,000 to $52,000 USD?</p>

<p>One way to get the 95% confidence prediction intervals for a deep learning model is the bootstrap method:</p>
<ol>
  <li>Take the predictions from several randomly initialized models (we’ve got this thanks to our ensemble models)</li>
  <li>Measure the standard deviation of the predictions</li>
  <li>Multiply the standard deviation by 1.96 (assuming the distribution is Gaussian/Normal, 95% of observations fall within 1.96 standard deviations of the mean)</li>
  <li>To get the prediction interval upper and lower bounds, add and subtract the value obtained in (3) to the mean/median of the predictions made in (1)</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Find the upper and lower bounds of ensemble predictions
</span><span class="k">def</span> <span class="nf">get_upper_lower</span><span class="p">(</span><span class="n">preds</span><span class="p">):</span> <span class="c1"># 1. Take the predictions from a number of randomely initialized models
</span>
  <span class="c1"># 2. Measure the standard deviation of the predictions
</span>  <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">reduce_std</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="c1"># 3. Multiply the standard deviation by 1.96
</span>  <span class="n">interval</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">std</span>

  <span class="c1"># 4. Get the prediction interval upper and lower bounds
</span>  <span class="n">preds_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">preds_mean</span> <span class="o">-</span> <span class="n">interval</span><span class="p">,</span> <span class="n">preds_mean</span> <span class="o">+</span> <span class="n">interval</span>

  <span class="k">return</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span>

<span class="c1"># Get the upper and lower bounds of the 95% percent prediction interval
</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="nf">get_upper_lower</span><span class="p">(</span><span class="n">preds</span><span class="o">=</span><span class="n">ensemble_preds</span><span class="p">)</span>
<span class="n">lower</span><span class="p">[:</span><span class="mi">50</span><span class="p">],</span> <span class="n">upper</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(&lt;tf.Tensor: shape=(50,), dtype=float32, numpy=
 array([8708.557 , 8696.403 , 8985.789 , 8608.548 , 8654.208 , 8618.757 ,
        8596.346 , 8390.076 , 8381.68  , 8471.399 , 8111.1455, 8029.3145,
        7973.0103, 7530.3247, 7146.0054, 7196.9727, 6991.8696, 7113.163 ,
        7010.447 , 7454.8364, 7300.8003, 7680.4487, 7498.997 , 7331.4663,
        7259.7803, 7248.139 , 7122.48  , 7333.116 , 7449.793 , 7482.997 ,
        7492.511 , 7290.5005, 7179.2397, 7137.6616, 7133.5776, 7178.6895,
        7004.6035, 7053.5903, 6804.3096, 6504.0044, 7224.831 , 7040.462 ,
        7050.7827, 7149.843 , 7143.1523, 7051.0903, 7172.766 , 7169.413 ,
        7118.5444, 7175.342 ], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(50,), dtype=float32, numpy=
 array([8834.213 , 8824.282 , 9100.967 , 8806.909 , 8830.386 , 8803.55  ,
        8700.283 , 8543.566 , 8501.297 , 8549.821 , 8263.096 , 8155.122 ,
        8105.276 , 7690.238 , 7409.222 , 7404.1777, 7190.555 , 7307.878 ,
        7221.9663, 7597.1606, 7477.779 , 7805.5913, 7647.176 , 7441.222 ,
        7371.3936, 7346.4097, 7248.3687, 7433.4062, 7555.7783, 7581.409 ,
        7594.821 , 7363.4634, 7260.0073, 7201.6577, 7211.11  , 7264.5703,
        7140.159 , 7130.696 , 6917.385 , 6629.984 , 7535.4316, 7254.802 ,
        7266.94  , 7356.8486, 7397.5107, 7298.522 , 7250.187 , 7238.009 ,
        7217.886 , 7241.8047], dtype=float32)&gt;)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get the median/mean of our ensemble preds
</span><span class="n">ensemble_median</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">median</span><span class="p">(</span><span class="n">ensemble_preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot the median of our ensemble preds along with the prediction intervals (where the predictions fall between)
</span><span class="n">offset</span><span class="o">=</span><span class="mi">500</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="n">offset</span><span class="p">:],</span> <span class="n">y_test</span><span class="p">[</span><span class="n">offset</span><span class="p">:],</span> <span class="sh">"</span><span class="s">g</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Test Data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="n">offset</span><span class="p">:],</span> <span class="n">ensemble_median</span><span class="p">[</span><span class="n">offset</span><span class="p">:],</span> <span class="sh">"</span><span class="s">k-</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Ensemble Median</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Date</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">BTC Price (USD)</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># To plot the upper and lower bounds, let's use fill_between
</span><span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="n">offset</span><span class="p">:],</span>
                 <span class="p">(</span><span class="n">lower</span><span class="p">)[</span><span class="n">offset</span><span class="p">:],</span>
                 <span class="p">(</span><span class="n">upper</span><span class="p">)[</span><span class="n">offset</span><span class="p">:],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Prediction Intervals</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">"</span><span class="s">upper left</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/ensemble-median-graph.png" alt="" /></p>

<p>So far all of our models’ predictions have been lagging behind the test data…</p>

<p>They’re replicating what the naive model does and just predict the previous timesteps as the next timestep.’</p>

<blockquote>
  <p><strong>Note:</strong> These prediction intervals are estimates themselves and they have been created with the assumption that our models’ data is from a normal distribution.</p>
</blockquote>

<h2 id="aside-two-types-of-uncertainty-coconut-and-subway">Aside: two types of uncertainty (coconut and subway)</h2>

<p>Uncertainty estimates in machine learning seek to qualitatively and quantitatively answer the questions:</p>
<ol>
  <li>What can my model know? (with perfect data, what’s possible for a model to learn?)</li>
  <li>What doesn’t my model know? (what can a model never predict? Or would it be helpful if a model could you that when it’s making a prediction, it doesn’t actually know if it’s right or not?)</li>
</ol>

<p>There are two major types of uncertainty in machine learning:</p>
<ul>
  <li><strong>Aleatoric uncertainty</strong> - this type of uncertainty cannot be reduced and it is often referred to as “data” uncertainty or “subway” uncertainty</li>
  <li><strong>Epistemic uncertainty</strong> - this type of uncertainty can be reduced, it is also referred to as “model” or “coconut” uncertainty.</li>
</ul>

<h2 id="model-9-train-a-model-on-the-full-historical-data-to-make-predictions-into-the-future">Model 9: Train a model on the full historical data to make predictions into the future</h2>

<p>So far all of our models have predicted on the test dataset, however, this is only a peseudofuture.</p>

<p>Let’s now build a model which is capable of predicting into the future.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">7</span>

<span class="n">bitcoin_prices_windowed</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/df-5.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Train model on entire data to make prediction for the next day
</span><span class="n">X_all</span> <span class="o">=</span> <span class="n">bitcoin_prices_windowed</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">block_reward</span><span class="sh">"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">dropna</span><span class="p">().</span><span class="nf">to_numpy</span><span class="p">()</span> <span class="c1"># only want prices, our future model can be a univariate model
</span><span class="n">y_all</span> <span class="o">=</span> <span class="n">bitcoin_prices_windowed</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()[</span><span class="sh">"</span><span class="s">Price</span><span class="sh">"</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">()</span>

<span class="c1"># Turn data into efficient running tensors
</span><span class="n">features_dataset_all</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">X_all</span><span class="p">)</span>
<span class="n">labels_dataset_all</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">y_all</span><span class="p">)</span>

<span class="c1"># Combine features and labels
</span><span class="n">dataset_all</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">zip</span><span class="p">((</span><span class="n">features_dataset_all</span><span class="p">,</span> <span class="n">labels_dataset_all</span><span class="p">))</span>

<span class="c1"># Batch and prefetch for optimital performance
</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">dataset_all</span> <span class="o">=</span> <span class="n">dataset_all</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">).</span><span class="nf">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>

<span class="c1"># Set seed
</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Create model
</span><span class="n">model_9</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
  <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="sh">"</span><span class="s">he_normal</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
  <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="sh">"</span><span class="s">he_normal</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">),</span>
  <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">HORIZON</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">model_9</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Compile the model
</span><span class="n">model_9</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">mae</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># Fit the model
</span><span class="n">model_9</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">dataset_all</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>
<p>Now that we have trained <code class="language-plaintext highlighter-rouge">model_9</code>, let’s see if we can make some predictions about the “future.”</p>

<h3 id="make-predictions-for-the-future">Make predictions for the future</h3>

<p><strong>Note:</strong> Of the time of this notebook, it is January 2024, and our data only goes up till May 2021. At the time of this, there is an updated Bitcoin data, but this can be helpful to compare the actual prices of bitcoin on the dates we will predict.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># How many timesteps to predict into the future?
</span><span class="n">INTO_FUTURE</span> <span class="o">=</span> <span class="mi">14</span>
</code></pre></div></div>

<p>To make predictions for the future we want a function that:</p>

<ol>
  <li>Takes an input:
    <ul>
      <li>a list of values (Bitcoin historical data)</li>
      <li>a trained model (such as <code class="language-plaintext highlighter-rouge">model_9</code>)</li>
      <li>a window into the future to predict (our <code class="language-plaintext highlighter-rouge">INTO_FUTURE</code> variable)</li>
      <li>the window size a model was trained  on (<code class="language-plaintext highlighter-rouge">WINDOW_SIZE</code>) - the model can only predict the same kind of data it was trained on</li>
    </ul>
  </li>
  <li>Creates an empty list for future forecasts (this will be returned at the end of the function when it’s full of predictions) and extracts the last <code class="language-plaintext highlighter-rouge">WINDOW_SIZE</code> values from the input values</li>
  <li>Loop <code class="language-plaintext highlighter-rouge">INTO_FUTURE</code> times making a prediction on <code class="language-plaintext highlighter-rouge">WINDOW_SIZE</code> sequences which update to remove the first value and append the latest prediction</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 1. Create function to make predictions into the future
</span><span class="k">def</span> <span class="nf">make_future_forecast</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">into_future</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
  <span class="sh">"""</span><span class="s">
  Makes future forecasts into_future steps after values ends.

  Returns future forecasts as list of floats.
  </span><span class="sh">"""</span>

  <span class="c1"># 2. Make an empty list for future forecasts/prepare data to forecast on
</span>  <span class="n">future_forecast</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">last_window</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="n">WINDOW_SIZE</span><span class="p">:]</span> <span class="c1"># only want preds from the last window (this will get updated)
</span>
  <span class="c1"># 3. Make INTO_FUTURE number of predictions, altering the data which gets predicted on each time
</span>  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">into_future</span><span class="p">):</span>

    <span class="c1"># Predict on last window then append it again, again, again (model starts to make forecasts on its own forecasts)
</span>    <span class="n">future_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">last_window</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Predicting on: </span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="n">last_window</span><span class="si">}</span><span class="s"> -&gt; Prediction: </span><span class="si">{</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">future_pred</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># Append predictions to future_forecast
</span>    <span class="n">future_forecast</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">future_pred</span><span class="p">).</span><span class="nf">numpy</span><span class="p">())</span>

    <span class="c1"># Update last window with new pred and get WINDOW_SIZE most recent preds (model was trained on WINDOW_SIZE windows)
</span>    <span class="n">last_window</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">last_window</span><span class="p">,</span> <span class="n">future_pred</span><span class="p">)[</span><span class="o">-</span><span class="n">WINDOW_SIZE</span><span class="p">:]</span>

  <span class="k">return</span> <span class="n">future_forecast</span>
</code></pre></div></div>

<p><strong>How this method works:</strong></p>

<p>Let’s say our data is <code class="language-plaintext highlighter-rouge">[1, 2, 3, 4, 5, 6, 7]</code>. This is the most recent data you have, and it’s 7 elements long because <code class="language-plaintext highlighter-rouge">WINDOW_SIZE = 7</code>.
<br /><br />
First Iteration:</p>

<ol>
  <li>The model predicts the next value based on <code class="language-plaintext highlighter-rouge">last_window</code>. Let’s say this prediction is 8.</li>
  <li>You append this prediction to <code class="language-plaintext highlighter-rouge">last_window</code>: <code class="language-plaintext highlighter-rouge">[1, 2, 3, 4, 5, 6, 7, 8]</code>.</li>
  <li>Now, you need to ensure <code class="language-plaintext highlighter-rouge">last_window</code> has only the latest 7 elements. So, you take <code class="language-plaintext highlighter-rouge">[-7:]</code> of this array, which gives <code class="language-plaintext highlighter-rouge">[2, 3, 4, 5, 6, 7, 8].</code></li>
  <li><code class="language-plaintext highlighter-rouge">last_window</code> is now <code class="language-plaintext highlighter-rouge">[2, 3, 4, 5, 6, 7, 8].</code>
<br /><br /></li>
</ol>

<p>Second Iteration:</p>

<ol>
  <li>The model now uses <code class="language-plaintext highlighter-rouge">[2, 3, 4, 5, 6, 7, 8]</code> to make a new prediction. Let’s say it predicts 9.</li>
  <li>Append 9 to the array: <code class="language-plaintext highlighter-rouge">[2, 3, 4, 5, 6, 7, 8, 9].</code></li>
  <li>Again, take the last 7 elements: <code class="language-plaintext highlighter-rouge">[3, 4, 5, 6, 7, 8, 9].</code></li>
  <li><code class="language-plaintext highlighter-rouge">last_window</code> becomes <code class="language-plaintext highlighter-rouge">[3, 4, 5, 6, 7, 8, 9].</code>
<br /><br />
This process repeats for each prediction. With each iteration, <code class="language-plaintext highlighter-rouge">last_window</code> is updated to always contain the 7 most recent values: the oldest one is dropped, and the newest prediction is included. Over time, as you continue making predictions, <code class="language-plaintext highlighter-rouge">last_window</code> consists more and more of the model’s own predictions rather than the original historical data.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make forecasts into the future
</span><span class="n">future_forecast</span> <span class="o">=</span> <span class="nf">make_future_forecast</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">y_all</span><span class="p">,</span>
                                       <span class="n">model</span><span class="o">=</span><span class="n">model_9</span><span class="p">,</span>
                                       <span class="n">into_future</span><span class="o">=</span><span class="n">INTO_FUTURE</span><span class="p">,</span>
                                       <span class="n">window_size</span><span class="o">=</span><span class="n">WINDOW_SIZE</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1/1 [==============================] - 0s 52ms/step
Predicting on: 
 [56573.5554719  52147.82118698 49764.1320816  50032.69313676
 47885.62525472 45604.61575361 43144.47129086] -&gt; Prediction: 54647.390625

1/1 [==============================] - 0s 17ms/step
Predicting on: 
 [52147.82118698 49764.1320816  50032.69313676 47885.62525472
 45604.61575361 43144.47129086 54647.390625  ] -&gt; Prediction: 51310.3671875

1/1 [==============================] - 0s 18ms/step
Predicting on: 
 [49764.1320816  50032.69313676 47885.62525472 45604.61575361
 43144.47129086 54647.390625   51310.3671875 ] -&gt; Prediction: 49274.3671875

1/1 [==============================] - 0s 17ms/step
Predicting on: 
 [50032.69313676 47885.62525472 45604.61575361 43144.47129086
 54647.390625   51310.3671875  49274.3671875 ] -&gt; Prediction: 48256.7265625

1/1 [==============================] - 0s 24ms/step
Predicting on: 
 [47885.62525472 45604.61575361 43144.47129086 54647.390625
 51310.3671875  49274.3671875  48256.7265625 ] -&gt; Prediction: 44655.06640625

1/1 [==============================] - 0s 18ms/step
Predicting on: 
 [45604.61575361 43144.47129086 54647.390625   51310.3671875
 49274.3671875  48256.7265625  44655.06640625] -&gt; Prediction: 46321.8125

1/1 [==============================] - 0s 20ms/step
Predicting on: 
 [43144.47129086 54647.390625   51310.3671875  49274.3671875
 48256.7265625  44655.06640625 46321.8125    ] -&gt; Prediction: 45425.6796875

1/1 [==============================] - 0s 22ms/step
Predicting on: 
 [54647.390625   51310.3671875  49274.3671875  48256.7265625
 44655.06640625 46321.8125     45425.6796875 ] -&gt; Prediction: 53306.96875

1/1 [==============================] - 0s 18ms/step
Predicting on: 
 [51310.3671875  49274.3671875  48256.7265625  44655.06640625
 46321.8125     45425.6796875  53306.96875   ] -&gt; Prediction: 50442.71484375

1/1 [==============================] - 0s 21ms/step
Predicting on: 
 [49274.3671875  48256.7265625  44655.06640625 46321.8125
 45425.6796875  53306.96875    50442.71484375] -&gt; Prediction: 47496.1875

1/1 [==============================] - 0s 18ms/step
Predicting on: 
 [48256.7265625  44655.06640625 46321.8125     45425.6796875
 53306.96875    50442.71484375 47496.1875    ] -&gt; Prediction: 46633.56640625

1/1 [==============================] - 0s 21ms/step
Predicting on: 
 [44655.06640625 46321.8125     45425.6796875  53306.96875
 50442.71484375 47496.1875     46633.56640625] -&gt; Prediction: 43047.8984375

1/1 [==============================] - 0s 18ms/step
Predicting on: 
 [46321.8125     45425.6796875  53306.96875    50442.71484375
 47496.1875     46633.56640625 43047.8984375 ] -&gt; Prediction: 47194.47265625

1/1 [==============================] - 0s 17ms/step
Predicting on: 
 [45425.6796875  53306.96875    50442.71484375 47496.1875
 46633.56640625 43047.8984375  47194.47265625] -&gt; Prediction: 47042.22265625
</code></pre></div></div>

<h3 id="plot-future-forecasts">Plot future forecasts</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_future_dates</span><span class="p">(</span><span class="n">start_date</span><span class="p">,</span> <span class="n">into_future</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Returns array of datetime values ranging from start_date to start_date+into_future
  </span><span class="sh">"""</span>
  <span class="n">start_date</span> <span class="o">=</span> <span class="n">start_date</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">timedelta64</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="sh">"</span><span class="s">D</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># Specifiy start date, "D" stands for day
</span>  <span class="n">end_date</span> <span class="o">=</span> <span class="n">start_date</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">timedelta64</span><span class="p">(</span><span class="n">into_future</span><span class="p">,</span> <span class="sh">"</span><span class="s">D</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># Specifiy end date
</span>  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start_date</span><span class="p">,</span> <span class="n">end_date</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">datetime64[D]</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># return a date range between start and end date
</span>
<span class="c1"># Last timestep of timesteps (currently np.datetime64 format)
</span><span class="n">last_timestep</span> <span class="o">=</span> <span class="n">bitcoin_prices</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">last_timestep</span><span class="p">,</span> <span class="nf">type</span><span class="p">(</span><span class="n">last_timestep</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: (Timestamp('2021-05-18 00:00:00'), pandas._libs.tslibs.timestamps.Timestamp)</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get next two weeks of timesteps
</span><span class="n">next_time_steps</span> <span class="o">=</span> <span class="nf">get_future_dates</span><span class="p">(</span><span class="n">start_date</span><span class="o">=</span><span class="n">last_timestep</span><span class="p">,</span>
                                   <span class="n">into_future</span><span class="o">=</span><span class="n">INTO_FUTURE</span><span class="p">)</span>
<span class="n">next_time_steps</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['2021-05-19', '2021-05-20', '2021-05-21', '2021-05-22',
       '2021-05-23', '2021-05-24', '2021-05-25', '2021-05-26',
       '2021-05-27', '2021-05-28', '2021-05-29', '2021-05-30',
       '2021-05-31', '2021-06-01'], dtype='datetime64[D]')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Insert last timestep/final price into next time steps and future forecasts so the plot looks complete
</span><span class="n">next_time_steps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="n">next_time_steps</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">last_timestep</span><span class="p">)</span>
<span class="n">future_forecast</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="n">future_forecast</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">btc_price</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">next_time_steps</span><span class="p">,</span> <span class="n">future_forecast</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array(['2021-05-18', '2021-05-19', '2021-05-20', '2021-05-21',
        '2021-05-22', '2021-05-23', '2021-05-24', '2021-05-25',
        '2021-05-26', '2021-05-27', '2021-05-28', '2021-05-29',
        '2021-05-30', '2021-05-31', '2021-06-01'], dtype='datetime64[D]'),
 array([43144.473, 54647.39 , 51310.367, 49274.367, 48256.727, 44655.066,
        46321.812, 45425.68 , 53306.97 , 50442.715, 47496.188, 46633.566,
        43047.9  , 47194.473, 47042.223], dtype=float32))
</code></pre></div></div>

<p>We need to do this, or else our graph will be disjointed since we did not calculate the price for the first time step in the future forecast.</p>

<p>By inserting the last timestep or final price into the beginning of both <code class="language-plaintext highlighter-rouge">next_time_steps</code> and <code class="language-plaintext highlighter-rouge">future_forecast</code>, we ensure a smooth transition between the historical data and the future predictions, creating a visually complete graph.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot future prices predictions of Bitcoin
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">bitcoin_prices</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">btc_price</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">2500</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Actual BTC Price</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">next_time_steps</span><span class="p">,</span> <span class="n">future_forecast</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Predicted BTC Price</span><span class="sh">"</span><span class="p">);</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/bitcoin-predictions-graph.png" alt="" /></p>

<p>So our model’s predictions are way off from the actual Bitcoin prices from these dates. For example, on 2021-05-21, our model predicted the price of Bitcoin is $41,737.05 when the actual amount was $37,304.69 for the close price.</p>

<p>This isn’t a surprise since it seems like all the models we’ve built are replicating our naive forecast.</p>

<h2 id="model-10-why-forecasting-is-bs-the-turkey-problem">Model 10: Why forecasting is BS (The Turkey Problem)</h2>

<p>The “Turkey Problem,” is a metaphorical illustration used to explain the limitations and potential pitfalls of inductive reasoning, especially in forecasting and predicting future events.</p>

<p>The story involves a turkey that is fed every day by a farmer. The turkey, observing this daily pattern, concludes that the farmer will always feed it.</p>

<p>This conclusion, based on its past experiences, is dramatically proven wrong on the day before Thanksgiving when, instead of being fed, the turkey is killed.</p>

<p>So in our case, when we’re trying to predict the price of Bitcoin, we’ve got to remember that something totally unexpected could happen. Like, there could be a day when the price just tanks out of the blue, and our model wouldn’t see it coming because it’s never happened before.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Let's introduce a turkey problem to our BTC data (the price of BTC falls 100x in one day)
</span><span class="n">btc_price_turkey</span> <span class="o">=</span> <span class="n">btc_price</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">btc_price_turkey</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">btc_price_turkey</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">100</span> <span class="c1"># Change last day of our data to simulate bitcoin price crashing out of nowhere
</span>
<span class="c1"># Manufacture an extra price on the end (to showcase our Turkey problem)
</span><span class="n">btc_price_turkey</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[58788.2096789273,
 58102.1914262342,
 55715.5466512869,
 56573.5554719043,
 52147.8211869823,
 49764.1320815975,
 50032.6931367648,
 47885.6252547166,
 45604.6157536131,
 431.44471290860304]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get the timesteps for the trukey problem
</span><span class="n">btc_timesteps_turkey</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">bitcoin_prices</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">btc_timesteps_turkey</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['2021-05-09T00:00:00.000000000', '2021-05-10T00:00:00.000000000',
       '2021-05-11T00:00:00.000000000', '2021-05-12T00:00:00.000000000',
       '2021-05-13T00:00:00.000000000', '2021-05-14T00:00:00.000000000',
       '2021-05-15T00:00:00.000000000', '2021-05-16T00:00:00.000000000',
       '2021-05-17T00:00:00.000000000', '2021-05-18T00:00:00.000000000'],
      dtype='datetime64[ns]')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">btc_timesteps_turkey</span><span class="p">,</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">btc_price_turkey</span><span class="p">,</span>
                 <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">BTC Price + Turkey Problem</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">start</span><span class="o">=</span><span class="mi">2500</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/turkey-graph.png" alt="" /></p>

<p>Now, we can see at the end of the graph, the price of Bitcoin suddenly drops like crazy. Let’s see how this one data point affects how our model learns.</p>

<h2 id="build-a-turkey-model-model-to-predict-on-turkey">Build a turkey model (model to predict on turkey)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Clone model 1 architecture for turkey model and fit turkey model on the turkey data
</span><span class="n">turkey_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">clone_model</span><span class="p">(</span><span class="n">model_1</span><span class="p">)</span>
<span class="n">turkey_model</span><span class="p">.</span><span class="n">_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">model_10_turkey_model</span><span class="sh">"</span>
<span class="n">turkey_model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">,</span>
                     <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">())</span>
<span class="n">turkey_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span>
                 <span class="n">y_train</span><span class="p">,</span>
                 <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                 <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                 <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nf">create_model_checkpoint</span><span class="p">(</span><span class="n">turkey_model</span><span class="p">.</span><span class="n">name</span><span class="p">)])</span>

<span class="c1"># Load best perforing model and evaluate on test data
</span><span class="n">turkey_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">model_experiments/model_10_turkey_model</span><span class="sh">"</span><span class="p">)</span>
<span class="n">turkey_model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>18/18 [==============================] - 0s 3ms/step - loss: 646.3936
646.3936157226562
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions with turkey model
</span><span class="n">turkey_preds</span> <span class="o">=</span> <span class="nf">make_preds</span><span class="p">(</span><span class="n">turkey_model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate turkey preds
</span><span class="n">turkey_results</span> <span class="o">=</span> <span class="nf">evaluate_preds</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
                                <span class="n">y_pred</span><span class="o">=</span><span class="n">turkey_preds</span><span class="p">)</span>
<span class="n">turkey_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 17125.197,
 'mse': 614165000.0,
 'rmse': 23706.53,
 'mape': 121.29158,
 'mase': 26.501297}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print model_1 results
</span><span class="n">model_1_results</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mae': 573.91125,
 'mse': 1186394.6,
 'rmse': 1089.2174,
 'mape': 2.5553186,
 'mase': 1.0082031}
</code></pre></div></div>

<p>Woah! Our mae score for our turkey model is way off since our model did not see the last data point coming. To show this, let’s visualize our turkey model’s predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">offset</span> <span class="o">=</span> <span class="mi">300</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">btc_timesteps_turkey</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">):],</span>
                  <span class="n">values</span><span class="o">=</span><span class="n">btc_price_turkey</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">):],</span>
                  <span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span>
                  <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Turkey Test Data</span><span class="sh">"</span><span class="p">,</span>
                  <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">)</span>
<span class="nf">plot_time_series</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">btc_timesteps_turkey</span><span class="p">[</span><span class="o">-</span><span class="nf">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">):],</span>
                 <span class="n">values</span><span class="o">=</span><span class="n">turkey_preds</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Turkey Preds</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">start</span><span class="o">=</span><span class="n">offset</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/turkey-graph-2.png" alt="" /></p>

<p>So based on historical data, our model had no reason to predict the data point at the end where the price drops severely.</p>

<p>The model can only predict on the same distribution it was trained on which is the “Turkey Problem”. A model could make correct predictions for 1000 days straight, but on day 1001, something catastrophic could happen and the model did not see it coming.</p>

<h3 id="compare-models">Compare models</h3>

<p>After a bunch of experimenting, let’s compare all our models against each other.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Compare different model results (w = window, h = horizon, e.g. w=7 means a window size of 7)
</span><span class="n">model_results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">naive_model</span><span class="sh">"</span><span class="p">:</span> <span class="n">naive_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_1_dense_w7_h1</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_1_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_2_dense_w30_h1</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_2_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_3_dense_w30_h7</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_3_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_4_CONV1D</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_4_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_5_LSTM</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_5_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_6_multivariate</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_6_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_7_NBEATS</span><span class="sh">"</span><span class="p">:</span> <span class="n">model_7_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_8_ensemble</span><span class="sh">"</span><span class="p">:</span> <span class="n">ensemble_results</span><span class="p">,</span>
                              <span class="sh">"</span><span class="s">model_10_turkey</span><span class="sh">"</span><span class="p">:</span> <span class="n">turkey_results</span><span class="p">}).</span><span class="n">T</span>
<span class="n">model_results</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/model-results.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sort model results by MAE and plot them
</span><span class="n">model_results</span><span class="p">[[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">]].</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">bar</span><span class="sh">"</span><span class="p">);</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Output: </code></p>

<p><img src="/images/bitcoin-images/model-results-graph.png" alt="" /></p>

<p>It seems our best model with the lowest mae score (lower is better) is <code class="language-plaintext highlighter-rouge">model_7_NBEATS</code>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>After a bunch of experimenting with 10 models, I have come to the conclusion that forecasting is not always possible. Some things are easier to forecast than others. For example, predicting the sunrise on a morning can be forecasted easily however, forecasting a lottery ticket number is impossible. In our case, BitCoin is just too difficult to forecast. Generally, forecasting is good based on these factors:</p>

<ol>
  <li>How much data is available?</li>
  <li>How similar is the past to the future?</li>
  <li>Whether the forecasts can affect the thing we are trying to forecast.</li>
  <li>Understanding the factors that contribute to the forecast.</li>
</ol>

<p>Playing around with different models taught me that forecasting stuff like Bitcoin isn’t always spot on. It really boils down to how good your data is and if what happened before tells us anything about what might happen next. It’s a handy tool, but definitely has its limits, especially with tricky things like crypto. Regardless of how things turned out, this was an interesting project. This taught me to be wary of any models that claim to predict the stock market or crypto.</p>

<h2 id="the-full-code">The Full Code</h2>

<p>You can check out all the code together on my <a href="https://github.com/samikamal21/Predicting-Bitcoin">Predicting-Bitcoin repository.</a></p>

        
      </section>

      <footer class="page__meta">
        
        


        

      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Sami Kamal. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
